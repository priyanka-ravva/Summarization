{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## some points:\n",
    "\n",
    "# #Reference summary & System summary \n",
    "\n",
    "# Here we have to check how much of System summary is captured of Reference summary.\n",
    "# ---> It can be exact match overlapping\n",
    "# ---> Semantically can be right [ here is the challenge how we solve this problem ]\n",
    "\n",
    "\n",
    "# Basically Recall will tell how much of Reference summary is covered by System summary.\n",
    "\n",
    "# some existing methods used Recall, Precision, and F1_score.\n",
    "\n",
    "# [ They have base information as reference summary, with this did some experiments like N-gram overlapping, edit distance, similarity method, contextual embeddings methods ]\n",
    "\n",
    "\n",
    "\n",
    "# But in our case,\n",
    "\n",
    "# ##### Reference Summary == Original article(input document) & System summary == Human annotated summary\n",
    "\n",
    "# ### Params:\n",
    "# 1. Readability (Perplexity maybe?)\n",
    "# 2. Creativity(Novelty) (Precision)\n",
    "# 3. Relevance (Bertscore+LSI (index overlap))\n",
    "# 4. Conciseness (Compression Ratio)\n",
    "\n",
    "\n",
    "# ----> Relevance:\n",
    "    \n",
    "# how the Relevance information covered in Summary(Representation/formation): \n",
    "# how much information is copied, \n",
    "# how much information is creative,\n",
    "# the whole copied & creative information is understandable or not \n",
    "# and the whole information is in concise manner or not.\n",
    "\n",
    "\n",
    "# Copying     --> Precision, Recall based we can get [ Is there any other complications to identifying the copying ]\n",
    "\n",
    "# Creativity  --> [1-Precision] - Any other problems ?? how can we improve this ??\n",
    "\n",
    "# Conciseness --> Need to have a better telugu tokenizer\n",
    "\n",
    "# Relevance   --> any clustering, similarity, Ranking method [ Extractive way..?? ] -- [Have to work on this....!!]\n",
    "\n",
    "\n",
    "\n",
    "# ###########Task1: Data spliting ##################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ###########Task2: Basic AEM pipeline #################\n",
    "\n",
    "\n",
    "# Excellent Summary:\n",
    "\n",
    "# ---> copying: , novelty: , conciseness: , Relevance:\n",
    "\n",
    "# Good Summary:\n",
    "\n",
    "# ---> copying: , novelty: , conciseness: , Relevance:\n",
    "\n",
    "# Average Summary:\n",
    "\n",
    "# ---> copying: , novelty: , conciseness: , Relevance:\n",
    "\n",
    "# Bad Summary\n",
    "\n",
    "# ---> copying: , novelty: , conciseness: , Relevance:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import json\n",
    "f = open('dataset.json',) \n",
    "corpus_info = json.load(f) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open('rouge_scores.json',) \n",
    "rouge_scores_info = json.load(f2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rouge_score_based_categorized_data_information.json') as data_file:    \n",
    "    catergorized_info = json.load(data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good samples =26594\n",
      "26594\n",
      "\n",
      "\n",
      "Unigrams_Novelty_range >=0 --> #of samples = 26594\n",
      "Unigrams_Novelty_range >=5 --> #of samples = 23048\n",
      "Unigrams_Novelty_range >=10 --> #of samples = 18932\n",
      "Unigrams_Novelty_range >=15 --> #of samples = 14840\n",
      "Unigrams_Novelty_range >=20 --> #of samples = 11623\n",
      "Unigrams_Novelty_range >=25 --> #of samples = 8848\n",
      "Unigrams_Novelty_range >=30 --> #of samples = 6586\n",
      "Unigrams_Novelty_range >=35 --> #of samples = 4924\n",
      "Unigrams_Novelty_range >=40 --> #of samples = 3610\n",
      "Unigrams_Novelty_range >=45 --> #of samples = 2498\n",
      "Unigrams_Novelty_range >=50 --> #of samples = 1728\n",
      "Unigrams_Novelty_range >=55 --> #of samples = 1044\n",
      "Unigrams_Novelty_range >=60 --> #of samples = 625\n",
      "Unigrams_Novelty_range >=65 --> #of samples = 336\n",
      "Unigrams_Novelty_range >=70 --> #of samples = 178\n",
      "Unigrams_Novelty_range >=75 --> #of samples = 82\n",
      "Unigrams_Novelty_range >=80 --> #of samples = 34\n",
      "Unigrams_Novelty_range >=85 --> #of samples = 18\n",
      "Unigrams_Novelty_range >=90 --> #of samples = 16\n",
      "Unigrams_Novelty_range >=95 --> #of samples = 8\n",
      "Unigrams_Novelty_range >=100 --> #of samples = 0\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "Bigrams_Novelty_range >=0 --> #of samples = 26594\n",
      "Bigrams_Novelty_range >=5 --> #of samples = 26066\n",
      "Bigrams_Novelty_range >=10 --> #of samples = 25014\n",
      "Bigrams_Novelty_range >=15 --> #of samples = 23418\n",
      "Bigrams_Novelty_range >=20 --> #of samples = 21354\n",
      "Bigrams_Novelty_range >=25 --> #of samples = 19131\n",
      "Bigrams_Novelty_range >=30 --> #of samples = 16724\n",
      "Bigrams_Novelty_range >=35 --> #of samples = 14330\n",
      "Bigrams_Novelty_range >=40 --> #of samples = 12170\n",
      "Bigrams_Novelty_range >=45 --> #of samples = 10000\n",
      "Bigrams_Novelty_range >=50 --> #of samples = 8382\n",
      "Bigrams_Novelty_range >=55 --> #of samples = 6579\n",
      "Bigrams_Novelty_range >=60 --> #of samples = 5225\n",
      "Bigrams_Novelty_range >=65 --> #of samples = 3943\n",
      "Bigrams_Novelty_range >=70 --> #of samples = 2880\n",
      "Bigrams_Novelty_range >=75 --> #of samples = 2025\n",
      "Bigrams_Novelty_range >=80 --> #of samples = 1269\n",
      "Bigrams_Novelty_range >=85 --> #of samples = 699\n",
      "Bigrams_Novelty_range >=90 --> #of samples = 314\n",
      "Bigrams_Novelty_range >=95 --> #of samples = 108\n",
      "Bigrams_Novelty_range >=100 --> #of samples = 46\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "Trigrams_Novelty_range >=0 --> #of samples = 26594\n",
      "Trigrams_Novelty_range >=5 --> #of samples = 26383\n",
      "Trigrams_Novelty_range >=10 --> #of samples = 25974\n",
      "Trigrams_Novelty_range >=15 --> #of samples = 25332\n",
      "Trigrams_Novelty_range >=20 --> #of samples = 24421\n",
      "Trigrams_Novelty_range >=25 --> #of samples = 23206\n",
      "Trigrams_Novelty_range >=30 --> #of samples = 21571\n",
      "Trigrams_Novelty_range >=35 --> #of samples = 19926\n",
      "Trigrams_Novelty_range >=40 --> #of samples = 18144\n",
      "Trigrams_Novelty_range >=45 --> #of samples = 16122\n",
      "Trigrams_Novelty_range >=50 --> #of samples = 14409\n",
      "Trigrams_Novelty_range >=55 --> #of samples = 12201\n",
      "Trigrams_Novelty_range >=60 --> #of samples = 10431\n",
      "Trigrams_Novelty_range >=65 --> #of samples = 8538\n",
      "Trigrams_Novelty_range >=70 --> #of samples = 6844\n",
      "Trigrams_Novelty_range >=75 --> #of samples = 5366\n",
      "Trigrams_Novelty_range >=80 --> #of samples = 3913\n",
      "Trigrams_Novelty_range >=85 --> #of samples = 2673\n",
      "Trigrams_Novelty_range >=90 --> #of samples = 1580\n",
      "Trigrams_Novelty_range >=95 --> #of samples = 728\n",
      "Trigrams_Novelty_range >=100 --> #of samples = 320\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "4_grams_Novelty_range >=0 --> #of samples = 26594\n",
      "4_grams_Novelty_range >=5 --> #of samples = 26483\n",
      "4_grams_Novelty_range >=10 --> #of samples = 26256\n",
      "4_grams_Novelty_range >=15 --> #of samples = 25885\n",
      "4_grams_Novelty_range >=20 --> #of samples = 25432\n",
      "4_grams_Novelty_range >=25 --> #of samples = 24774\n",
      "4_grams_Novelty_range >=30 --> #of samples = 23887\n",
      "4_grams_Novelty_range >=35 --> #of samples = 22721\n",
      "4_grams_Novelty_range >=40 --> #of samples = 21458\n",
      "4_grams_Novelty_range >=45 --> #of samples = 19949\n",
      "4_grams_Novelty_range >=50 --> #of samples = 18524\n",
      "4_grams_Novelty_range >=55 --> #of samples = 16621\n",
      "4_grams_Novelty_range >=60 --> #of samples = 14842\n",
      "4_grams_Novelty_range >=65 --> #of samples = 12934\n",
      "4_grams_Novelty_range >=70 --> #of samples = 11000\n",
      "4_grams_Novelty_range >=75 --> #of samples = 9111\n",
      "4_grams_Novelty_range >=80 --> #of samples = 7180\n",
      "4_grams_Novelty_range >=85 --> #of samples = 5282\n",
      "4_grams_Novelty_range >=90 --> #of samples = 3618\n",
      "4_grams_Novelty_range >=95 --> #of samples = 2032\n",
      "4_grams_Novelty_range >=100 --> #of samples = 1012\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "Rouge_L_Novelty_range >=0 --> #of samples = 26594\n",
      "Rouge_L_Novelty_range >=5 --> #of samples = 25265\n",
      "Rouge_L_Novelty_range >=10 --> #of samples = 23971\n",
      "Rouge_L_Novelty_range >=15 --> #of samples = 22301\n",
      "Rouge_L_Novelty_range >=20 --> #of samples = 20286\n",
      "Rouge_L_Novelty_range >=25 --> #of samples = 18021\n",
      "Rouge_L_Novelty_range >=30 --> #of samples = 15464\n",
      "Rouge_L_Novelty_range >=35 --> #of samples = 12831\n",
      "Rouge_L_Novelty_range >=40 --> #of samples = 10470\n",
      "Rouge_L_Novelty_range >=45 --> #of samples = 7959\n",
      "Rouge_L_Novelty_range >=50 --> #of samples = 6090\n",
      "Rouge_L_Novelty_range >=55 --> #of samples = 4075\n",
      "Rouge_L_Novelty_range >=60 --> #of samples = 2659\n",
      "Rouge_L_Novelty_range >=65 --> #of samples = 1538\n",
      "Rouge_L_Novelty_range >=70 --> #of samples = 819\n",
      "Rouge_L_Novelty_range >=75 --> #of samples = 385\n",
      "Rouge_L_Novelty_range >=80 --> #of samples = 138\n",
      "Rouge_L_Novelty_range >=85 --> #of samples = 43\n",
      "Rouge_L_Novelty_range >=90 --> #of samples = 18\n",
      "Rouge_L_Novelty_range >=95 --> #of samples = 10\n",
      "Rouge_L_Novelty_range >=100 --> #of samples = 0\n"
     ]
    }
   ],
   "source": [
    "################## reading the json file for further ualitative qanalysis ##############\n",
    "\n",
    "import json\n",
    "\n",
    "#fname = open(\"dataset.json\",)\n",
    "#corpus_dict = json.load(fname)\n",
    "\n",
    "\n",
    "### loading json file\n",
    "f = open('rouge_scores.json',) \n",
    "data = json.load(f) \n",
    "print(\"good samples =%d\"%len(data))\n",
    "\n",
    "\n",
    "list_samples = list(data.keys())\n",
    "print(len(list_samples))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, 101, 5):\n",
    "    unigrams = [ sample for sample in list_samples if(data[sample]['novelty']['rouge-1']>=i) ] \n",
    "    print(\"Unigrams_Novelty_range >=%d --> #of samples = %d\"%(i, len(unigrams)))\n",
    "print(\"\\n---------------------------------------\\n\")  \n",
    "\n",
    "\n",
    "for i in range(0, 101, 5):\n",
    "    bigrams = [ sample for sample in list_samples if(data[sample]['novelty']['rouge-2']>=i) ] \n",
    "    print(\"Bigrams_Novelty_range >=%d --> #of samples = %d\"%(i, len(bigrams)))\n",
    "print(\"\\n---------------------------------------\\n\")    \n",
    "\n",
    "\n",
    "for i in range(0, 101, 5):\n",
    "    trigrams = [ sample for sample in list_samples if(data[sample]['novelty']['rouge-3']>=i) ] \n",
    "    print(\"Trigrams_Novelty_range >=%d --> #of samples = %d\"%(i, len(trigrams)))\n",
    "print(\"\\n---------------------------------------\\n\")    \n",
    "\n",
    "for i in range(0, 101, 5):\n",
    "    four_grams = [ sample for sample in list_samples if(data[sample]['novelty']['rouge-4']>=i) ] \n",
    "    print(\"4_grams_Novelty_range >=%d --> #of samples = %d\"%(i, len(four_grams)))\n",
    "    #print(\"bigrams \", len(bigrams))\n",
    "print(\"\\n---------------------------------------\\n\")\n",
    "\n",
    "\n",
    "for i in range(0, 101, 5):\n",
    "    Ngrams_L = [ sample for sample in list_samples if(data[sample]['novelty']['rouge-L']>=i) ] \n",
    "    print(\"Rouge_L_Novelty_range >=%d --> #of samples = %d\"%(i, len(Ngrams_L)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams_Novelty_range >=100 --> #of samples = 23206\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "Sample_num= 25801, novelty_rouge1 = 52.27, novelty_rouge2 = 72.09, novelty_rouge3 = 80.95  \n",
      "article: \n",
      "కడప కలెక్టరేట్లో బిఆర్ అంబేద్కర్ విగ్రహాన్ని తొలగించి, ఆ విగ్రహాన్ని ఏర్పాటు చేసిన వారిని రిమాండుకు పంపించటాన్ని సిపిఎం రాష్ట్ర కార్యదర్శి పి.మధు బుధవారం ఒక ప్రకటనలో ఖండించారు. గత కలెక్టర్ ఆ విగ్రహం ఏర్పాటుకు అనుమతి ఇచ్చినట్లు తెలిపారు. కాని అందుకు అనుమతిలేదంటూ ప్రస్తుత కలెక్టర్ ఆ విగ్రహాన్ని క్రెన్లతో తొలగించటం శోచనీయమన్నారు. విగ్రహం ఏర్పాటు చేసిన పలు సంఘాలకు చెందిన 13 మందిని అరెస్టు చేసి రిమాండుకు పంపించటం దుర్మార్గమని విమర్శించారు. అంబేద్కర్ 125 వ జయంతి సందర్భంగా పార్లమెంట్లోనూ, శాసనసభలోనూ ప్రత్యేక చర్చ తరుణంలోనే కడపలో ఇలాంటి ఘటన జరగటం అంబేద్కర్ను అవమా నించటమేనన్నారు. ఈ ఘటనపై ప్రభుత్వం తక్షణమే సమగ్ర విచారణ చేయాలని, కలెక్టర్పై చర్య తీసుకోవాలని ఆయన డిమాండు చేశారు.\n",
      "\n",
      "\n",
      "summary: \n",
      "﻿కడప కలెక్టరేట్లో బిఆర్ అంబేద్కర్ విగ్రహాన్ని తొలగించి, ఆ విగ్రహాన్ని ఏర్పాటు చేసిన వారిపై రిమాండు పెంచడాన్ని సిపిఎం రాష్ట్ర కార్యదర్శి పి మధు ఖండించారు. అంబేద్కర్ 125వ జయంతి సంబరాలు జరుపుటకు పార్లమెంట్ లోనూ మరియు శాసనసభలోనూ ప్రత్యేక చర్చలు జరుగుతున్న సమయంలో ఇలా జరగడం అంబేద్కర్ ను అవమానించడమేనని, దీనిపై ప్రభుత్వం చర్యలు తీసుకోవాలని ఆయన డిమాండ్ చేశారు.\n",
      "\n",
      "---------------- WX formate ------------------\n",
      "\n",
      "Article:\n",
      "kadapa kaleVktaretlo biAr aMbexkar vigrahAnni woVlagiMci, A vigrahAnni erpAtu cesina vArini rimAMduku paMpiMcatAnni sipieVM rARtra kAryaxarSi pi.maXu buXavAraM oVka prakatanalo KaMdiMcAru. gawa kaleVktar A vigrahaM erpAtuku anumawi iccinatlu weVlipAru. kAni aMxuku anumawilexaMtU praswuwa kaleVktar A vigrahAnni kreVnlawo woVlagiMcataM SocanIyamannAru. vigrahaM erpAtu cesina palu saMGAlaku ceVMxina 13 maMxini areVstu cesi rimAMduku paMpiMcataM xurmArgamani vimarSiMcAru. aMbexkar 125 va jayaMwi saMxarBaMgA pArlameVMtlonU, SAsanasaBalonU prawyeka carca waruNaMlone kadapalo ilAMti Gatana jaragataM aMbexkarnu avamA niMcatamenannAru. I GatanapE praBuwvaM wakRaName samagra vicAraNa ceyAlani, kaleVktarpE carya wIsukovAlani Ayana dimAMdu ceSAru.\n",
      "\n",
      "\n",
      "Summary:\n",
      "kadapa kaleVktaretlo biAr aMbexkar vigrahAnni woVlagiMci, A vigrahAnni erpAtu cesina vAripE rimAMdu peVMcadAnni sipieVM rARtra kAryaxarSi pi maXu KaMdiMcAru. aMbexkar 125va jayaMwi saMbarAlu jaruputaku pArlameVMt lonU mariyu SAsanasaBalonU prawyeka carcalu jaruguwunna samayaMlo ilA jaragadaM aMbexkar nu avamAniMcadamenani, xInipE praBuwvaM caryalu wIsukovAlani Ayana dimAMd ceSAru.\n",
      "\n",
      "=============================================================\n",
      "\n",
      "Sample_num= 14278, novelty_rouge1 = 17.86, novelty_rouge2 = 40.74, novelty_rouge3 = 53.85  \n",
      "article: \n",
      "మహిళాభివృద్ధే లక్ష్యంగా ఏర్పడిన భారతీయ మహిళా బ్యాంకు (బీఎంబీ) ఎస్బీఐలో విలీనం చేసేందుకు కేంద్రం నిర్ణయించింది. మరింత మందికి చేరువయ్యే ఉద్దేశంతో మహిళా బ్యాంకును ఎస్బీఐలో విలీనం చేయనున్నట్లు ఆర్థికశాఖ ఓ ప్రకటనలో వెల్లడించింది. ఎస్బీఐ విస్తృతి ఎక్కువగా ఉండటంతో మహిళలకు మరింత మేలు జరుగుతుందని ప్రకటనలో ఆర్థికశాఖ పేర్కొంది. మహిళా బ్యాంకు నిర్వహణ, పరిపాలన వ్యవహారాలకు అయ్యే ఖర్చు చాలా ఎక్కువ. అదే ఖర్చుతో ఎస్బీఐ ద్వారా మహిళలకు మరింత మెరుగ్గా రుణాలను, సేవలను అందించవచ్చని ఆర్థికశాఖ వెల్లడించింది. దేశవ్యాప్తంగా ఇప్పటి వరకు మహిళల కోసం ప్రత్యేకంగా 126 శాఖలను ఎస్బీఐ నిర్వహిస్తోంది. భారతీయ మహిళాబ్యాంకును 2013లో స్థాపించారు. దాదాపు అన్ని రాష్ట్రాల్లో దీనికి శాఖలు ఉన్నాయి. దేశవ్యాప్తంగా 103 శాఖలతో రూ.1600 కోట్ల టర్నోవర్ సాధించింది.\n",
      "\n",
      "\n",
      "summary: \n",
      "2013లో స్థాపించిన 126 శాఖలు గల భారతీయ మహిళాబ్యాంకు నిర్వహణ, పరిపాలన వ్యవహారాలకు అయ్యే ఖర్చు చాలా ఎక్కువగా ఉండటం వల్ల ఎస్బీఐలో విలీనం చేయనున్నట్లు ఆర్థికశాఖ వెల్లడించింది. దేశవ్యాప్తంగా 103 శాఖలతో రూ.1600 కోట్ల టర్నోవర్ సాధించింది.\n",
      "\n",
      "---------------- WX formate ------------------\n",
      "\n",
      "Article:\n",
      "mahilYABivqxXe lakRyaMgA erpadina BArawIya mahilYA byAMku (bIeVMbI) eVsbIElo vilInaM ceseMxuku keMxraM nirNayiMciMxi. mariMwa maMxiki ceruvayye uxxeSaMwo mahilYA byAMkunu eVsbIElo vilInaM ceyanunnatlu ArWikaSAKa o prakatanalo veVlladiMciMxi. eVsbIE viswqwi eVkkuvagA uMdataMwo mahilYalaku mariMwa melu jaruguwuMxani prakatanalo ArWikaSAKa perkoVMxi. mahilYA byAMku nirvahaNa, paripAlana vyavahArAlaku ayye Karcu cAlA eVkkuva. axe Karcuwo eVsbIE xvArA mahilYalaku mariMwa meVruggA ruNAlanu, sevalanu aMxiMcavaccani ArWikaSAKa veVlladiMciMxi. xeSavyApwaMgA ippati varaku mahilYala kosaM prawyekaMgA 126 SAKalanu eVsbIE nirvahiswoMxi. BArawIya mahilYAbyAMkunu 2013lo sWApiMcAru. xAxApu anni rARtrAllo xIniki SAKalu unnAyi. xeSavyApwaMgA 103 SAKalawo rU.1600 kotla tarnovar sAXiMciMxi.\n",
      "\n",
      "\n",
      "Summary:\n",
      "2013lo sWApiMcina 126 SAKalu gala BArawIya mahilYAbyAMku nirvahaNa, paripAlana vyavahArAlaku ayye Karcu cAlA eVkkuvagA uMdataM valla eVsbIElo vilInaM ceyanunnatlu ArWikaSAKa veVlladiMciMxi. xeSavyApwaMgA 103 SAKalawo rU.1600 kotla tarnovar sAXiMciMxi.\n",
      "\n",
      "=============================================================\n",
      "\n",
      "Sample_num= 10936, novelty_rouge1 = 31.37, novelty_rouge2 = 50.00, novelty_rouge3 = 65.31  \n",
      "article: \n",
      "﻿అపఖ్యాతి మూటగట్టుకున్న పార్క్ స్ట్రీట్ సామూహిక అత్యాచారం కేసుకు సంబంధించి ముగ్గురిని దోషులుగా కోర్టు గురువారం తేల్చింది. 2012 ఫిబ్రవరిలో జరిగిన ఈ కేసుకు సంబంధించి ఇద్దరు నిందితులు ఇంకా పరారీలో ఉన్నారు. రుమన్ ఖాన్, నాసర్ఖాన్, సుమిత్ బజాజ్లను నేరస్తులుగా పేర్కొంటూ సిటీ సెషన్స్ కోర్టు న్యాయమూర్తి చిరంజీబ్ భట్టాచార్య తీర్పునిచ్చారు. కాగా, వీరికి శిక్షను శుక్రవారం ఖరారు చేయనున్నారు. ఐపిసిలోని సెక్షన్ 376(2)(జి) సామూహిక అత్యాచారం, 120బి(నేరపూరిత కుట్ర), 506(నేరపూరిత బెదిరింపులు) ఇంకా పలు సెక్షన్ల కింద దోషులుగా నిర్ధారించారు. ఖాదర్ఖాన్, మరో నిందితుడు అలీలను పోలీసులు ఇంకా నిర్బంధంలోకి తీసుకోవాల్సి ఉంది. బాధితురాలు సుజెత్ జోర్దాన్ ఈ ఏడాది మార్చిలో మృతిచెందిన విషయం విదితమే. తన పేరును బహిరంగపర్చడంలో ఎలాంటి అభ్యంతరం లేదని బాధితురాలు బహిరంగంగా చెబుతుండే వారు. పార్క్ స్ట్రీట్లోని ఓ నైట్ క్లబ్ నుండి ఆమెను కారులో అపహరించుకు పోయిన కామాంధులు కదులుతున్న కారులోనే అతి దారుణంగా అత్యాచారానికి పాల్పడ్డారు. అనంతరం వారు ఆమెను రోడ్డుపక్కన పడేసి పరారయ్యారు.\n",
      "\n",
      "\n",
      "summary: \n",
      "﻿పార్క్ స్ట్రీట్లోని ఓ నైట్ క్లబ్ నుండి బాధితురాలు సుజెత్ జోర్దాన్ను కారులో అపహరించి ఐదుగురు కామాంధులు కదులుతున్న కారులోనే అతి దారుణంగా అత్యాచారానికి పాల్పడి తర్వాత ఆమెను రోడ్డుపక్కన పడేసి పారిపోయారు. దీనికి సంబంధించిన ముగ్గురిని దోషులుగా కోర్టు తేల్చగా, ఇద్దరు నిందితులు ఇంకా పరారీలో ఉన్నారు. ఆ ముగ్గురు దోషులకు ఐపిసిలోని సెక్షన్ 376(2)(జి) సామూహిక అత్యాచారం, 120బి, 506 ఇంకా కొన్ని సెక్షన్ల కింద దోషులుగా నిర్ధారించారు.\n",
      "\n",
      "---------------- WX formate ------------------\n",
      "\n",
      "Article:\n",
      "apaKyAwi mUtagattukunna pArk strIt sAmUhika awyAcAraM kesuku saMbaMXiMci muggurini xoRulugA kortu guruvAraM welciMxi. 2012 Pibravarilo jarigina I kesuku saMbaMXiMci ixxaru niMxiwulu iMkA parArIlo unnAru. ruman KAn, nAsarKAn, sumiw bajAjlanu neraswulugA perkoVMtU sitI seVRans kortu nyAyamUrwi ciraMjIb BattAcArya wIrpuniccAru. kAgA, vIriki SikRanu SukravAraM KarAru ceyanunnAru. Episiloni seVkRan 376(2)(ji) sAmUhika awyAcAraM, 120bi(nerapUriwa kutra), 506(nerapUriwa beVxiriMpulu) iMkA palu seVkRanla kiMxa xoRulugA nirXAriMcAru. KAxarKAn, maro niMxiwudu alIlanu polIsulu iMkA nirbaMXaMloki wIsukovAlsi uMxi. bAXiwurAlu sujeVw jorxAn I edAxi mArcilo mqwiceVMxina viRayaM vixiwame. wana perunu bahiraMgaparcadaMlo eVlAMti aByaMwaraM lexani bAXiwurAlu bahiraMgaMgA ceVbuwuMde vAru. pArk strItloni o nEt klab nuMdi AmeVnu kArulo apahariMcuku poyina kAmAMXulu kaxuluwunna kArulone awi xAruNaMgA awyAcArAniki pAlpaddAru. anaMwaraM vAru AmeVnu roddupakkana padesi parArayyAru.\n",
      "\n",
      "\n",
      "Summary:\n",
      "pArk strItloni o nEt klab nuMdi bAXiwurAlu sujeVw jorxAnnu kArulo apahariMci Exuguru kAmAMXulu kaxuluwunna kArulone awi xAruNaMgA awyAcArAniki pAlpadi warvAwa AmeVnu roddupakkana padesi pAripoyAru. xIniki saMbaMXiMcina muggurini xoRulugA kortu welcagA, ixxaru niMxiwulu iMkA parArIlo unnAru. A mugguru xoRulaku Episiloni seVkRan 376(2)(ji) sAmUhika awyAcAraM, 120bi, 506 iMkA koVnni seVkRanla kiMxa xoRulugA nirXAriMcAru.\n",
      "\n",
      "=============================================================\n",
      "\n",
      "Sample_num= 20563, novelty_rouge1 = 19.61, novelty_rouge2 = 32.00, novelty_rouge3 = 51.02  \n",
      "article: \n",
      "﻿అలెప్పొ, సిరియాల నుంచి పౌరుల తరలింపును రెబల్స్ అడ్డుకుంటున్నారని మిలటరీ వర్గాలు సోమవారం తెలిపాయి. సిరియా-రష్యాల మధ్య కాల్పుల విరమణ ఒప్పందం జరిగిన నేపధ్యంలో రెబల్స్ 24 గంటలకు పైగా కాల్పులు జరిపి ప్రజల కదలికలను అడ్డుకున్నారు. ముఖ్యంగా బస్టన్ తదితర ప్రాంతాల నుంచి ప్రజలు తరలి వెళ్ళకుండా అడ్డుకుంటున్నారని ఆ వర్గాలు తెలిపాయి. తరలి వెళ్ళిన వారికి సహాయం అందించేందుకు నిబంధనలు రూపొందించామని ఆ ప్రాంత గవర్నర్ మీడియాకు తెలిపారు. తరలి వెళ్ళడానికి ప్రయత్నించిన వారిలో డజను మందికి పైగా గాయపడ్డారని చెప్పారు. పౌరుల తరలింపును రెబల్స్ అడ్డుకోవడం వరసగా ఇది మూడవ రోజు. పౌరుల తరలింపు ప్రక్రియలో సిరియా, రష్యా అధికారులు పాల్గొంటున్నారు. ఇంటర్నేషనల్ రెడ్ క్రాస్ సంస్థ నుంచి కూడా కొంతమంది అధికారులు పాల్గొంటున్నారని వారు తెలిపారు. బస్టన్ అల్-ఖాస్సర్ కారిడాన్ ద్వారా వేలాది కుటుంబాలు తరలి వెళ్ళేందుకు ప్రయత్నిం చాయి. వీరిపై కూడా రెబల్స్ కాల్పులు జరిపారు.\n",
      "\n",
      "\n",
      "summary: \n",
      "﻿సిరియా-రష్యాల మధ్య కాల్పుల విరమణ ఒప్పందం జరిగినందున రెబల్స్ 24 గంటలకు పైగా కాల్పులు జరిపి ప్రజల కదలికలను అడ్డుకోవడమే కాకుండా ప్రజలు తరలి వెళ్ళకుండా అడ్డుకుంటున్నారని మిలటరీ వర్గాలు తెలిపాయి. అయితే తరలి వెళ్ళిన వారికి సహాయం అందించడానికి నిబంధనలు రూపొందించామని ఆ ప్రాంత గవర్నర్ మీడియాకు తెలిపారు. ఈ కార్యక్రమంలో సిరియా, రష్యా అధికారులే కాకుండా ఇంటర్నేషనల్ రెడ్ క్రాస్ సంస్థ నుంచి కూడా కొంతమంది అధికారులు పాల్గొంటున్నారు.\n",
      "\n",
      "---------------- WX formate ------------------\n",
      "\n",
      "Article:\n",
      "aleVppoV, siriyAla nuMci pOrula waraliMpunu reVbals addukuMtunnArani milatarI vargAlu somavAraM weVlipAyi. siriyA-raRyAla maXya kAlpula viramaNa oVppaMxaM jarigina nepaXyaMlo reVbals 24 gaMtalaku pEgA kAlpulu jaripi prajala kaxalikalanu addukunnAru. muKyaMgA bastan waxiwara prAMwAla nuMci prajalu warali veVlYlYakuMdA addukuMtunnArani A vargAlu weVlipAyi. warali veVlYlYina vAriki sahAyaM aMxiMceMxuku nibaMXanalu rUpoVMxiMcAmani A prAMwa gavarnar mIdiyAku weVlipAru. warali veVlYlYadAniki prayawniMcina vArilo dajanu maMxiki pEgA gAyapaddArani ceVppAru. pOrula waraliMpunu reVbals addukovadaM varasagA ixi mUdava roju. pOrula waraliMpu prakriyalo siriyA, raRyA aXikArulu pAlgoVMtunnAru. iMtarneRanal reVd krAs saMsWa nuMci kUdA koVMwamaMxi aXikArulu pAlgoVMtunnArani vAru weVlipAru. bastan al-KAssar kAridAn xvArA velAxi kutuMbAlu warali veVlYlYeMxuku prayawniM cAyi. vIripE kUdA reVbals kAlpulu jaripAru.\n",
      "\n",
      "\n",
      "Summary:\n",
      "siriyA-raRyAla maXya kAlpula viramaNa oVppaMxaM jariginaMxuna reVbals 24 gaMtalaku pEgA kAlpulu jaripi prajala kaxalikalanu addukovadame kAkuMdA prajalu warali veVlYlYakuMdA addukuMtunnArani milatarI vargAlu weVlipAyi. ayiwe warali veVlYlYina vAriki sahAyaM aMxiMcadAniki nibaMXanalu rUpoVMxiMcAmani A prAMwa gavarnar mIdiyAku weVlipAru. I kAryakramaMlo siriyA, raRyA aXikArule kAkuMdA iMtarneRanal reVd krAs saMsWa nuMci kUdA koVMwamaMxi aXikArulu pAlgoVMtunnAru.\n",
      "\n",
      "=============================================================\n",
      "\n",
      "Sample_num= 19406, novelty_rouge1 = 13.33, novelty_rouge2 = 35.59, novelty_rouge3 = 51.72  \n",
      "article: \n",
      "విజయనగరం బొబ్బొలి వైసిపి ఎమ్మెల్యే సుజయ కృష్ణ రంగారావు విజయవాడలో బుధవారం సిఎం చంద్రబాబునాయుడు సమక్షంలో తెలుగుదేశం పార్టీలో చేరారు. పలువురు ఎంపిటిసి, జెడ్పిటిసిల సభ్యులతో కలిసి వచ్చిన ఆయనకు చంద్రబాబు పచ్చ కండువా కప్పి పార్టీలోకి ఆహ్వానించారు. నియోజకవర్గ అభివృద్ధి కోసమే తాను టిడిపిలోకి వచ్చినట్లు రంగారావు తెలిపారు. రెండేళ్ల పాలనలో చంద్రబాబు రాష్ట్రాన్ని ఎంతో అభివృద్ధి చేశారన్నారు. విజయనగరం జిల్లా అభివృద్ధిపై ముఖ్యమంత్రికి విజన్ ఉందని, ఆయన సహకారంతో జిల్లాను అభివృద్ధి చేస్తామన్నారు. కోట్ల రూపాయిల ప్రజాధనాన్ని దోచుకున్న వారు నాయకులుగా చెలామణి అవుతున్నారని ఈ సందర్భంగా కేంద్రమంత్రి పూసపాటి అశోక్ గజపతి రాజు విమర్శించారు. ఈ కార్యక్రమంలో ఉపముఖ్యమంత్రి ఎన్ చినరాజప్ప, మంత్రులు మృణాళిని, గంటా శ్రీనివాసరావు, టిడిపి ఏపి అధ్యక్షులు కళా వెంకట్రావు పాల్గొన్నారు.\n",
      "\n",
      "\n",
      "summary: \n",
      "బొబ్బొలి వైసిపి ఎమ్మెల్యే సుజయ కృష్ణ రంగారావు పలువురు ఎంపిటిసి, జెడ్పిటిసిలతో వచ్చి తెలుగుదేశం పార్టీలో చేరగా, ఆయనకు చంద్రబాబు పచ్చ కండువా కప్పి పార్టీలోకి ఆహ్వానించారు. రెండేళ్ల పాలనలో చంద్రబాబు రాష్ట్రాన్ని ఎంతో అభివృద్ధి చేశారని, విజయనగరం జిల్లా అభివృద్ధిపై ముఖ్యమంత్రికి విజన్ ఉందని, నియోజకవర్గ అభివృద్ధి కోసమే తాను టిడిపిలోకి వచ్చినట్లు ఆయన తెలిపారు. కేంద్రమంత్రి పూసపాటి అశోక్ గజపతి రాజు మట్లాడుతూ కోట్ల రూపాయిల ప్రజాధనాన్ని దోచుకున్న వారు నాయకులు అవుతున్నారని విమర్శించారు. ఈ కార్యక్రమంలో పలువురు నాయకులు పాల్గొన్నారు.\n",
      "\n",
      "---------------- WX formate ------------------\n",
      "\n",
      "Article:\n",
      "vijayanagaraM boVbboVli vEsipi eVmmeVlye sujaya kqRNa raMgArAvu vijayavAdalo buXavAraM sieVM caMxrabAbunAyudu samakRaMlo weVluguxeSaM pArtIlo cerAru. paluvuru eVMpitisi, jeVdpitisila saByulawo kalisi vaccina Ayanaku caMxrabAbu pacca kaMduvA kappi pArtIloki AhvAniMcAru. niyojakavarga aBivqxXi kosame wAnu tidipiloki vaccinatlu raMgArAvu weVlipAru. reVMdelYla pAlanalo caMxrabAbu rARtrAnni eVMwo aBivqxXi ceSArannAru. vijayanagaraM jillA aBivqxXipE muKyamaMwriki vijan uMxani, Ayana sahakAraMwo jillAnu aBivqxXi ceswAmannAru. kotla rUpAyila prajAXanAnni xocukunna vAru nAyakulugA ceVlAmaNi avuwunnArani I saMxarBaMgA keMxramaMwri pUsapAti aSok gajapawi rAju vimarSiMcAru. I kAryakramaMlo upamuKyamaMwri eVn cinarAjappa, maMwrulu mqNAlYini, gaMtA SrInivAsarAvu, tidipi epi aXyakRulu kalYA veVMkatrAvu pAlgoVnnAru.\n",
      "\n",
      "\n",
      "Summary:\n",
      "boVbboVli vEsipi eVmmeVlye sujaya kqRNa raMgArAvu paluvuru eVMpitisi, jeVdpitisilawo vacci weVluguxeSaM pArtIlo ceragA, Ayanaku caMxrabAbu pacca kaMduvA kappi pArtIloki AhvAniMcAru. reVMdelYla pAlanalo caMxrabAbu rARtrAnni eVMwo aBivqxXi ceSArani, vijayanagaraM jillA aBivqxXipE muKyamaMwriki vijan uMxani, niyojakavarga aBivqxXi kosame wAnu tidipiloki vaccinatlu Ayana weVlipAru. keMxramaMwri pUsapAti aSok gajapawi rAju matlAduwU kotla rUpAyila prajAXanAnni xocukunna vAru nAyakulu avuwunnArani vimarSiMcAru. I kAryakramaMlo paluvuru nAyakulu pAlgoVnnAru.\n",
      "\n",
      "=============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for i in range(0, 101, 5):\n",
    "trigrams = [ sample for sample in list_samples if(data[sample]['novelty']['rouge-3']>=25) ] \n",
    "print(\"Trigrams_Novelty_range >=%d --> #of samples = %d\"%(i, len(trigrams)))\n",
    "print(\"\\n---------------------------------------\\n\")    \n",
    "#print(trigrams[:10])\n",
    "\n",
    "n = 5\n",
    "import random\n",
    "random.seed(42)\n",
    "randome_samples = random.sample(trigrams, n)\n",
    "\n",
    "### wx formate:\n",
    "from wxconv import WXC\n",
    "con = WXC(order='utf2wx', lang= 'tel')\n",
    "\n",
    "\n",
    "\n",
    "for sample_num in randome_samples:\n",
    "    \n",
    "    n3 = data[sample_num]['novelty']['rouge-3']\n",
    "    n2 = data[sample_num]['novelty']['rouge-2']  \n",
    "    n1 = data[sample_num]['novelty']['rouge-1']\n",
    "    \n",
    "    p1 = data[sample_num]['copy_precision']['rouge-1']\n",
    "    p2 = data[sample_num]['copy_precision']['rouge-2']\n",
    "    p3 = data[sample_num]['copy_precision']['rouge-3']\n",
    "    \n",
    "    #print(sample_num, n2, n3)\n",
    "    print(\"Sample_num= %s, novelty_rouge1 = %.2f, novelty_rouge2 = %.2f, novelty_rouge3 = %.2f  \"%(sample_num,n1,n2,n3))\n",
    "    #corpus_info[ trigrams[0]['article']]\n",
    "    print(\"article: \")\n",
    "    print(corpus_info[sample_num]['article']['content'])\n",
    "    print(\"\\n\")\n",
    "    print(\"summary: \")\n",
    "    print(corpus_info[ sample_num]['summary']['content'])\n",
    "    print(\"\\n---------------- WX formate ------------------\\n\")\n",
    "    print(\"Article:\")\n",
    "    print(con.convert(corpus_info[ sample_num]['article']['content']))\n",
    "    print(\"\\n\")\n",
    "    print(\"Summary:\")\n",
    "    print(con.convert(corpus_info[ sample_num]['summary']['content']))\n",
    "    print(\"\\n=============================================================\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "******************************************************** novelty **********************************************************\n",
      "\n",
      "\n",
      "======================================================= novelty_rouge_1 =================================================\n",
      "\n",
      "\n",
      "param = novelty_rouge_1 , bin_num = 10 , total_samples_in_a_bin = 7883 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=22, mean_article_tokens=90, median_article_tokens=85, mode_article_tokens=79 \n",
      "max_summary_tokens=329, min_summary_tokens=9, mean_summary_tokens=53, median_summary_tokens=49, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 6.50, mean_tokens_cr = 60.31, median_tokens_cr = 60.00, mode_tokens_cr = 50.00 \n",
      "In a bin out of 7883 samples, 301  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_1 , bin_num = 20 , total_samples_in_a_bin = 7368 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=302, min_article_tokens=22, mean_article_tokens=90, median_article_tokens=87, mode_article_tokens=91 \n",
      "max_summary_tokens=151, min_summary_tokens=10, mean_summary_tokens=51, median_summary_tokens=48, mode_summary_tokens=36 \n",
      "max_tokens_cr = 98.85, min_tokens_cr = 13.51, mean_tokens_cr = 58.37, median_tokens_cr = 57.89, mode_tokens_cr = 50.00 \n",
      "In a bin out of 7368 samples, 146  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_1 , bin_num = 30 , total_samples_in_a_bin = 4835 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=319, min_article_tokens=23, mean_article_tokens=92, median_article_tokens=89, mode_article_tokens=92 \n",
      "max_summary_tokens=159, min_summary_tokens=10, mean_summary_tokens=49, median_summary_tokens=47, mode_summary_tokens=44 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 4.39, mean_tokens_cr = 55.81, median_tokens_cr = 55.34, mode_tokens_cr = 50.00 \n",
      "In a bin out of 4835 samples, 50  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_1 , bin_num = 40 , total_samples_in_a_bin = 3019 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=258, min_article_tokens=22, mean_article_tokens=96, median_article_tokens=93, mode_article_tokens=74 \n",
      "max_summary_tokens=123, min_summary_tokens=8, mean_summary_tokens=48, median_summary_tokens=45, mode_summary_tokens=43 \n",
      "max_tokens_cr = 97.96, min_tokens_cr = 8.81, mean_tokens_cr = 52.75, median_tokens_cr = 52.26, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3019 samples, 25  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_1 , bin_num = 50 , total_samples_in_a_bin = 1932 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=24, mean_article_tokens=97, median_article_tokens=93, mode_article_tokens=88 \n",
      "max_summary_tokens=168, min_summary_tokens=11, mean_summary_tokens=46, median_summary_tokens=43, mode_summary_tokens=42 \n",
      "max_tokens_cr = 98.28, min_tokens_cr = 10.81, mean_tokens_cr = 50.24, median_tokens_cr = 49.02, mode_tokens_cr = 50.00 \n",
      "In a bin out of 1932 samples, 18  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_1 , bin_num = 60 , total_samples_in_a_bin = 972 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=255, min_article_tokens=24, mean_article_tokens=95, median_article_tokens=89, mode_article_tokens=86 \n",
      "max_summary_tokens=116, min_summary_tokens=10, mean_summary_tokens=43, median_summary_tokens=41, mode_summary_tokens=35 \n",
      "max_tokens_cr = 97.18, min_tokens_cr = 11.17, mean_tokens_cr = 48.46, median_tokens_cr = 47.09, mode_tokens_cr = 50.00 \n",
      "In a bin out of 972 samples, 6  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_1 , bin_num = 70 , total_samples_in_a_bin = 413 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=279, min_article_tokens=25, mean_article_tokens=93, median_article_tokens=86, mode_article_tokens=63 \n",
      "max_summary_tokens=111, min_summary_tokens=16, mean_summary_tokens=40, median_summary_tokens=37, mode_summary_tokens=36 \n",
      "max_tokens_cr = 90.77, min_tokens_cr = 7.17, mean_tokens_cr = 46.54, median_tokens_cr = 45.37, mode_tokens_cr = 50.00 \n",
      "In a bin out of 413 samples, 1  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_1 , bin_num = 80 , total_samples_in_a_bin = 139 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=208, min_article_tokens=26, mean_article_tokens=86, median_article_tokens=82, mode_article_tokens=65 \n",
      "max_summary_tokens=100, min_summary_tokens=14, mean_summary_tokens=37, median_summary_tokens=36, mode_summary_tokens=37 \n",
      "max_tokens_cr = 88.64, min_tokens_cr = 13.46, mean_tokens_cr = 46.63, median_tokens_cr = 46.97, mode_tokens_cr = 25.00 \n",
      "In a bin out of 139 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_1 , bin_num = 90 , total_samples_in_a_bin = 17 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=127, min_article_tokens=41, mean_article_tokens=83, median_article_tokens=81, mode_article_tokens=81 \n",
      "max_summary_tokens=61, min_summary_tokens=17, mean_summary_tokens=32, median_summary_tokens=33, mode_summary_tokens=35 \n",
      "max_tokens_cr = 75.61, min_tokens_cr = 21.67, mean_tokens_cr = 40.73, median_tokens_cr = 39.77, mode_tokens_cr = 21.67 \n",
      "In a bin out of 17 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_1 , bin_num = 100 , total_samples_in_a_bin = 16 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=211, min_article_tokens=46, mean_article_tokens=109, median_article_tokens=96, mode_article_tokens=46 \n",
      "max_summary_tokens=146, min_summary_tokens=23, mean_summary_tokens=52, median_summary_tokens=42, mode_summary_tokens=35 \n",
      "max_tokens_cr = 81.72, min_tokens_cr = 19.43, mean_tokens_cr = 51.38, median_tokens_cr = 52.28, mode_tokens_cr = 19.43 \n",
      "In a bin out of 16 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "======================================================= novelty_rouge_2 =================================================\n",
      "\n",
      "\n",
      "param = novelty_rouge_2 , bin_num = 10 , total_samples_in_a_bin = 1644 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=26, mean_article_tokens=97, median_article_tokens=89, mode_article_tokens=70 \n",
      "max_summary_tokens=329, min_summary_tokens=9, mean_summary_tokens=59, median_summary_tokens=55, mode_summary_tokens=61 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 11.72, mean_tokens_cr = 62.91, median_tokens_cr = 63.16, mode_tokens_cr = 50.00 \n",
      "In a bin out of 1644 samples, 110  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_2 , bin_num = 20 , total_samples_in_a_bin = 3784 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=246, min_article_tokens=22, mean_article_tokens=90, median_article_tokens=86, mode_article_tokens=81 \n",
      "max_summary_tokens=187, min_summary_tokens=12, mean_summary_tokens=54, median_summary_tokens=51, mode_summary_tokens=46 \n",
      "max_tokens_cr = 98.65, min_tokens_cr = 6.50, mean_tokens_cr = 61.89, median_tokens_cr = 62.00, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3784 samples, 172  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_2 , bin_num = 30 , total_samples_in_a_bin = 4561 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=302, min_article_tokens=22, mean_article_tokens=90, median_article_tokens=86, mode_article_tokens=77 \n",
      "max_summary_tokens=151, min_summary_tokens=13, mean_summary_tokens=52, median_summary_tokens=49, mode_summary_tokens=45 \n",
      "max_tokens_cr = 98.85, min_tokens_cr = 9.92, mean_tokens_cr = 59.61, median_tokens_cr = 59.15, mode_tokens_cr = 50.00 \n",
      "In a bin out of 4561 samples, 117  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_2 , bin_num = 40 , total_samples_in_a_bin = 4641 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=271, min_article_tokens=22, mean_article_tokens=89, median_article_tokens=86, mode_article_tokens=100 \n",
      "max_summary_tokens=134, min_summary_tokens=10, mean_summary_tokens=50, median_summary_tokens=47, mode_summary_tokens=39 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 13.51, mean_tokens_cr = 57.74, median_tokens_cr = 57.50, mode_tokens_cr = 50.00 \n",
      "In a bin out of 4641 samples, 65  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_2 , bin_num = 50 , total_samples_in_a_bin = 3974 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=296, min_article_tokens=22, mean_article_tokens=90, median_article_tokens=87, mode_article_tokens=92 \n",
      "max_summary_tokens=159, min_summary_tokens=11, mean_summary_tokens=48, median_summary_tokens=46, mode_summary_tokens=38 \n",
      "max_tokens_cr = 99.02, min_tokens_cr = 4.39, mean_tokens_cr = 55.61, median_tokens_cr = 55.06, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3974 samples, 36  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_2 , bin_num = 60 , total_samples_in_a_bin = 2896 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=319, min_article_tokens=24, mean_article_tokens=94, median_article_tokens=91, mode_article_tokens=74 \n",
      "max_summary_tokens=155, min_summary_tokens=10, mean_summary_tokens=49, median_summary_tokens=46, mode_summary_tokens=38 \n",
      "max_tokens_cr = 97.96, min_tokens_cr = 5.19, mean_tokens_cr = 54.18, median_tokens_cr = 54.05, mode_tokens_cr = 50.00 \n",
      "In a bin out of 2896 samples, 17  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_2 , bin_num = 70 , total_samples_in_a_bin = 2271 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=25, mean_article_tokens=97, median_article_tokens=94, mode_article_tokens=101 \n",
      "max_summary_tokens=132, min_summary_tokens=13, mean_summary_tokens=47, median_summary_tokens=44, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.28, min_tokens_cr = 9.95, mean_tokens_cr = 51.06, median_tokens_cr = 50.51, mode_tokens_cr = 50.00 \n",
      "In a bin out of 2271 samples, 19  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_2 , bin_num = 80 , total_samples_in_a_bin = 1642 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=252, min_article_tokens=24, mean_article_tokens=96, median_article_tokens=92, mode_article_tokens=88 \n",
      "max_summary_tokens=168, min_summary_tokens=11, mean_summary_tokens=44, median_summary_tokens=42, mode_summary_tokens=39 \n",
      "max_tokens_cr = 97.40, min_tokens_cr = 10.32, mean_tokens_cr = 49.02, median_tokens_cr = 47.96, mode_tokens_cr = 50.00 \n",
      "In a bin out of 1642 samples, 9  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_2 , bin_num = 90 , total_samples_in_a_bin = 881 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=279, min_article_tokens=24, mean_article_tokens=95, median_article_tokens=89, mode_article_tokens=86 \n",
      "max_summary_tokens=123, min_summary_tokens=8, mean_summary_tokens=41, median_summary_tokens=39, mode_summary_tokens=37 \n",
      "max_tokens_cr = 92.11, min_tokens_cr = 7.17, mean_tokens_cr = 46.56, median_tokens_cr = 45.33, mode_tokens_cr = 40.00 \n",
      "In a bin out of 881 samples, 2  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_2 , bin_num = 100 , total_samples_in_a_bin = 300 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=241, min_article_tokens=25, mean_article_tokens=92, median_article_tokens=88, mode_article_tokens=89 \n",
      "max_summary_tokens=146, min_summary_tokens=13, mean_summary_tokens=37, median_summary_tokens=35, mode_summary_tokens=33 \n",
      "max_tokens_cr = 88.64, min_tokens_cr = 12.45, mean_tokens_cr = 43.45, median_tokens_cr = 41.57, mode_tokens_cr = 33.33 \n",
      "In a bin out of 300 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "======================================================= novelty_rouge_3 =================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param = novelty_rouge_3 , bin_num = 10 , total_samples_in_a_bin = 646 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=33, mean_article_tokens=103, median_article_tokens=94, mode_article_tokens=79 \n",
      "max_summary_tokens=329, min_summary_tokens=9, mean_summary_tokens=63, median_summary_tokens=58, mode_summary_tokens=45 \n",
      "max_tokens_cr = 98.80, min_tokens_cr = 11.72, mean_tokens_cr = 62.13, median_tokens_cr = 62.20, mode_tokens_cr = 50.00 \n",
      "In a bin out of 646 samples, 40  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_3 , bin_num = 20 , total_samples_in_a_bin = 1613 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=287, min_article_tokens=22, mean_article_tokens=94, median_article_tokens=89, mode_article_tokens=74 \n",
      "max_summary_tokens=212, min_summary_tokens=11, mean_summary_tokens=59, median_summary_tokens=55, mode_summary_tokens=48 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 18.03, mean_tokens_cr = 64.27, median_tokens_cr = 64.29, mode_tokens_cr = 66.67 \n",
      "In a bin out of 1613 samples, 113  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_3 , bin_num = 30 , total_samples_in_a_bin = 2840 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=260, min_article_tokens=23, mean_article_tokens=91, median_article_tokens=87, mode_article_tokens=81 \n",
      "max_summary_tokens=174, min_summary_tokens=14, mean_summary_tokens=54, median_summary_tokens=52, mode_summary_tokens=46 \n",
      "max_tokens_cr = 98.65, min_tokens_cr = 9.92, mean_tokens_cr = 61.93, median_tokens_cr = 62.07, mode_tokens_cr = 50.00 \n",
      "In a bin out of 2840 samples, 131  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_3 , bin_num = 40 , total_samples_in_a_bin = 3542 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=249, min_article_tokens=23, mean_article_tokens=90, median_article_tokens=86, mode_article_tokens=79 \n",
      "max_summary_tokens=151, min_summary_tokens=12, mean_summary_tokens=52, median_summary_tokens=49, mode_summary_tokens=45 \n",
      "max_tokens_cr = 98.85, min_tokens_cr = 6.50, mean_tokens_cr = 60.14, median_tokens_cr = 59.83, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3542 samples, 101  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_3 , bin_num = 50 , total_samples_in_a_bin = 3997 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=302, min_article_tokens=22, mean_article_tokens=89, median_article_tokens=86, mode_article_tokens=78 \n",
      "max_summary_tokens=131, min_summary_tokens=10, mean_summary_tokens=50, median_summary_tokens=47, mode_summary_tokens=44 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 13.51, mean_tokens_cr = 58.09, median_tokens_cr = 57.63, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3997 samples, 60  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_3 , bin_num = 60 , total_samples_in_a_bin = 3719 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=282, min_article_tokens=22, mean_article_tokens=90, median_article_tokens=87, mode_article_tokens=71 \n",
      "max_summary_tokens=159, min_summary_tokens=12, mean_summary_tokens=49, median_summary_tokens=47, mode_summary_tokens=37 \n",
      "max_tokens_cr = 99.02, min_tokens_cr = 12.50, mean_tokens_cr = 56.61, median_tokens_cr = 56.38, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3719 samples, 36  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_3 , bin_num = 70 , total_samples_in_a_bin = 3470 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=319, min_article_tokens=22, mean_article_tokens=92, median_article_tokens=89, mode_article_tokens=75 \n",
      "max_summary_tokens=134, min_summary_tokens=11, mean_summary_tokens=48, median_summary_tokens=46, mode_summary_tokens=38 \n",
      "max_tokens_cr = 98.48, min_tokens_cr = 4.39, mean_tokens_cr = 54.97, median_tokens_cr = 54.40, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3470 samples, 28  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_3 , bin_num = 80 , total_samples_in_a_bin = 2978 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=24, mean_article_tokens=94, median_article_tokens=91, mode_article_tokens=101 \n",
      "max_summary_tokens=132, min_summary_tokens=10, mean_summary_tokens=47, median_summary_tokens=45, mode_summary_tokens=39 \n",
      "max_tokens_cr = 98.28, min_tokens_cr = 8.81, mean_tokens_cr = 52.41, median_tokens_cr = 51.96, mode_tokens_cr = 50.00 \n",
      "In a bin out of 2978 samples, 20  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_3 , bin_num = 90 , total_samples_in_a_bin = 2265 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=238, min_article_tokens=23, mean_article_tokens=95, median_article_tokens=92, mode_article_tokens=81 \n",
      "max_summary_tokens=168, min_summary_tokens=12, mean_summary_tokens=45, median_summary_tokens=43, mode_summary_tokens=43 \n",
      "max_tokens_cr = 97.40, min_tokens_cr = 9.95, mean_tokens_cr = 49.96, median_tokens_cr = 49.12, mode_tokens_cr = 50.00 \n",
      "In a bin out of 2265 samples, 14  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_3 , bin_num = 100 , total_samples_in_a_bin = 1524 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=279, min_article_tokens=24, mean_article_tokens=92, median_article_tokens=88, mode_article_tokens=65 \n",
      "max_summary_tokens=146, min_summary_tokens=8, mean_summary_tokens=40, median_summary_tokens=37, mode_summary_tokens=33 \n",
      "max_tokens_cr = 95.65, min_tokens_cr = 7.17, mean_tokens_cr = 46.26, median_tokens_cr = 44.80, mode_tokens_cr = 40.00 \n",
      "In a bin out of 1524 samples, 4  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "======================================================= novelty_rouge_4 =================================================\n",
      "\n",
      "\n",
      "param = novelty_rouge_4 , bin_num = 10 , total_samples_in_a_bin = 351 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=38, mean_article_tokens=104, median_article_tokens=96, mode_article_tokens=85 \n",
      "max_summary_tokens=329, min_summary_tokens=9, mean_summary_tokens=65, median_summary_tokens=59, mode_summary_tokens=66 \n",
      "max_tokens_cr = 98.80, min_tokens_cr = 11.72, mean_tokens_cr = 63.22, median_tokens_cr = 64.81, mode_tokens_cr = 50.00 \n",
      "In a bin out of 351 samples, 21  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_4 , bin_num = 20 , total_samples_in_a_bin = 859 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=299, min_article_tokens=33, mean_article_tokens=99, median_article_tokens=89, mode_article_tokens=88 \n",
      "max_summary_tokens=272, min_summary_tokens=15, mean_summary_tokens=61, median_summary_tokens=57, mode_summary_tokens=45 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 16.48, mean_tokens_cr = 63.82, median_tokens_cr = 64.00, mode_tokens_cr = 50.00 \n",
      "In a bin out of 859 samples, 74  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_4 , bin_num = 30 , total_samples_in_a_bin = 1538 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=282, min_article_tokens=22, mean_article_tokens=94, median_article_tokens=90, mode_article_tokens=64 \n",
      "max_summary_tokens=163, min_summary_tokens=11, mean_summary_tokens=58, median_summary_tokens=55, mode_summary_tokens=53 \n",
      "max_tokens_cr = 98.48, min_tokens_cr = 18.03, mean_tokens_cr = 63.72, median_tokens_cr = 64.00, mode_tokens_cr = 66.67 \n",
      "In a bin out of 1538 samples, 95  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_4 , bin_num = 40 , total_samples_in_a_bin = 2521 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=260, min_article_tokens=26, mean_article_tokens=92, median_article_tokens=87, mode_article_tokens=68 \n",
      "max_summary_tokens=174, min_summary_tokens=13, mean_summary_tokens=55, median_summary_tokens=52, mode_summary_tokens=46 \n",
      "max_tokens_cr = 98.65, min_tokens_cr = 9.92, mean_tokens_cr = 62.06, median_tokens_cr = 62.50, mode_tokens_cr = 50.00 \n",
      "In a bin out of 2521 samples, 112  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_4 , bin_num = 50 , total_samples_in_a_bin = 3193 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=249, min_article_tokens=23, mean_article_tokens=91, median_article_tokens=86, mode_article_tokens=70 \n",
      "max_summary_tokens=151, min_summary_tokens=12, mean_summary_tokens=52, median_summary_tokens=49, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.85, min_tokens_cr = 14.29, mean_tokens_cr = 59.76, median_tokens_cr = 59.06, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3193 samples, 80  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_4 , bin_num = 60 , total_samples_in_a_bin = 3478 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=302, min_article_tokens=22, mean_article_tokens=90, median_article_tokens=86, mode_article_tokens=78 \n",
      "max_summary_tokens=131, min_summary_tokens=13, mean_summary_tokens=51, median_summary_tokens=48, mode_summary_tokens=38 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 6.50, mean_tokens_cr = 58.48, median_tokens_cr = 58.36, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3478 samples, 53  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param = novelty_rouge_4 , bin_num = 70 , total_samples_in_a_bin = 3745 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=282, min_article_tokens=23, mean_article_tokens=90, median_article_tokens=87, mode_article_tokens=73 \n",
      "max_summary_tokens=159, min_summary_tokens=12, mean_summary_tokens=49, median_summary_tokens=47, mode_summary_tokens=39 \n",
      "max_tokens_cr = 99.02, min_tokens_cr = 15.71, mean_tokens_cr = 57.03, median_tokens_cr = 56.67, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3745 samples, 39  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_4 , bin_num = 80 , total_samples_in_a_bin = 3924 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=22, mean_article_tokens=91, median_article_tokens=88, mode_article_tokens=74 \n",
      "max_summary_tokens=134, min_summary_tokens=10, mean_summary_tokens=48, median_summary_tokens=46, mode_summary_tokens=42 \n",
      "max_tokens_cr = 98.48, min_tokens_cr = 11.71, mean_tokens_cr = 54.80, median_tokens_cr = 54.39, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3924 samples, 37  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_4 , bin_num = 90 , total_samples_in_a_bin = 3448 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=296, min_article_tokens=22, mean_article_tokens=94, median_article_tokens=91, mode_article_tokens=81 \n",
      "max_summary_tokens=132, min_summary_tokens=10, mean_summary_tokens=47, median_summary_tokens=45, mode_summary_tokens=39 \n",
      "max_tokens_cr = 98.28, min_tokens_cr = 4.39, mean_tokens_cr = 52.45, median_tokens_cr = 51.89, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3448 samples, 19  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_4 , bin_num = 100 , total_samples_in_a_bin = 3537 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=279, min_article_tokens=23, mean_article_tokens=92, median_article_tokens=88, mode_article_tokens=76 \n",
      "max_summary_tokens=168, min_summary_tokens=8, mean_summary_tokens=42, median_summary_tokens=39, mode_summary_tokens=37 \n",
      "max_tokens_cr = 97.40, min_tokens_cr = 7.17, mean_tokens_cr = 48.27, median_tokens_cr = 47.25, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3537 samples, 17  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "======================================================= novelty_rouge_L =================================================\n",
      "\n",
      "\n",
      "param = novelty_rouge_L , bin_num = 10 , total_samples_in_a_bin = 2696 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=22, mean_article_tokens=92, median_article_tokens=86, mode_article_tokens=70 \n",
      "max_summary_tokens=329, min_summary_tokens=9, mean_summary_tokens=54, median_summary_tokens=50, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.80, min_tokens_cr = 6.50, mean_tokens_cr = 60.96, median_tokens_cr = 60.76, mode_tokens_cr = 66.67 \n",
      "In a bin out of 2696 samples, 140  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_L , bin_num = 20 , total_samples_in_a_bin = 3811 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=302, min_article_tokens=22, mean_article_tokens=91, median_article_tokens=86, mode_article_tokens=62 \n",
      "max_summary_tokens=187, min_summary_tokens=10, mean_summary_tokens=52, median_summary_tokens=49, mode_summary_tokens=45 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 9.92, mean_tokens_cr = 59.99, median_tokens_cr = 59.72, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3811 samples, 127  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_L , bin_num = 30 , total_samples_in_a_bin = 4743 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=249, min_article_tokens=23, mean_article_tokens=90, median_article_tokens=87, mode_article_tokens=86 \n",
      "max_summary_tokens=212, min_summary_tokens=11, mean_summary_tokens=51, median_summary_tokens=48, mode_summary_tokens=44 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 14.29, mean_tokens_cr = 58.68, median_tokens_cr = 58.12, mode_tokens_cr = 50.00 \n",
      "In a bin out of 4743 samples, 115  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_L , bin_num = 40 , total_samples_in_a_bin = 5104 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=289, min_article_tokens=22, mean_article_tokens=91, median_article_tokens=88, mode_article_tokens=73 \n",
      "max_summary_tokens=159, min_summary_tokens=11, mean_summary_tokens=50, median_summary_tokens=47, mode_summary_tokens=38 \n",
      "max_tokens_cr = 98.73, min_tokens_cr = 5.19, mean_tokens_cr = 56.95, median_tokens_cr = 56.80, mode_tokens_cr = 50.00 \n",
      "In a bin out of 5104 samples, 77  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_L , bin_num = 50 , total_samples_in_a_bin = 4625 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=296, min_article_tokens=25, mean_article_tokens=92, median_article_tokens=89, mode_article_tokens=77 \n",
      "max_summary_tokens=155, min_summary_tokens=10, mean_summary_tokens=49, median_summary_tokens=47, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.48, min_tokens_cr = 4.39, mean_tokens_cr = 55.08, median_tokens_cr = 54.69, mode_tokens_cr = 50.00 \n",
      "In a bin out of 4625 samples, 50  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_L , bin_num = 60 , total_samples_in_a_bin = 3082 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=24, mean_article_tokens=94, median_article_tokens=92, mode_article_tokens=98 \n",
      "max_summary_tokens=168, min_summary_tokens=10, mean_summary_tokens=48, median_summary_tokens=46, mode_summary_tokens=41 \n",
      "max_tokens_cr = 98.48, min_tokens_cr = 10.97, mean_tokens_cr = 53.31, median_tokens_cr = 53.02, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3082 samples, 28  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_L , bin_num = 70 , total_samples_in_a_bin = 1745 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=319, min_article_tokens=23, mean_article_tokens=95, median_article_tokens=90, mode_article_tokens=88 \n",
      "max_summary_tokens=123, min_summary_tokens=8, mean_summary_tokens=45, median_summary_tokens=43, mode_summary_tokens=43 \n",
      "max_tokens_cr = 95.69, min_tokens_cr = 10.46, mean_tokens_cr = 49.86, median_tokens_cr = 49.11, mode_tokens_cr = 50.00 \n",
      "In a bin out of 1745 samples, 10  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_L , bin_num = 80 , total_samples_in_a_bin = 661 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=279, min_article_tokens=26, mean_article_tokens=93, median_article_tokens=89, mode_article_tokens=75 \n",
      "max_summary_tokens=111, min_summary_tokens=14, mean_summary_tokens=42, median_summary_tokens=40, mode_summary_tokens=37 \n",
      "max_tokens_cr = 89.66, min_tokens_cr = 7.17, mean_tokens_cr = 48.47, median_tokens_cr = 48.15, mode_tokens_cr = 50.00 \n",
      "In a bin out of 661 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_L , bin_num = 90 , total_samples_in_a_bin = 109 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=237, min_article_tokens=27, mean_article_tokens=95, median_article_tokens=90, mode_article_tokens=58 \n",
      "max_summary_tokens=100, min_summary_tokens=16, mean_summary_tokens=40, median_summary_tokens=37, mode_summary_tokens=37 \n",
      "max_tokens_cr = 86.84, min_tokens_cr = 14.77, mean_tokens_cr = 44.91, median_tokens_cr = 44.35, mode_tokens_cr = 32.46 \n",
      "In a bin out of 109 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = novelty_rouge_L , bin_num = 100 , total_samples_in_a_bin = 18 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=211, min_article_tokens=46, mean_article_tokens=106, median_article_tokens=92, mode_article_tokens=46 \n",
      "max_summary_tokens=146, min_summary_tokens=23, mean_summary_tokens=51, median_summary_tokens=42, mode_summary_tokens=35 \n",
      "max_tokens_cr = 81.72, min_tokens_cr = 19.43, mean_tokens_cr = 52.09, median_tokens_cr = 52.28, mode_tokens_cr = 19.43 \n",
      "In a bin out of 18 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "******************************************************** copy_precision **********************************************************\n",
      "\n",
      "\n",
      "======================================================= precision_copy_rouge_1 =================================================\n",
      "\n",
      "\n",
      "param = precision_copy_rouge_1 , bin_num = 10 , total_samples_in_a_bin = 16 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=211, min_article_tokens=46, mean_article_tokens=109, median_article_tokens=96, mode_article_tokens=46 \n",
      "max_summary_tokens=146, min_summary_tokens=23, mean_summary_tokens=52, median_summary_tokens=42, mode_summary_tokens=35 \n",
      "max_tokens_cr = 81.72, min_tokens_cr = 19.43, mean_tokens_cr = 51.38, median_tokens_cr = 52.28, mode_tokens_cr = 19.43 \n",
      "In a bin out of 16 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_1 , bin_num = 20 , total_samples_in_a_bin = 18 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=127, min_article_tokens=41, mean_article_tokens=82, median_article_tokens=81, mode_article_tokens=81 \n",
      "max_summary_tokens=61, min_summary_tokens=17, mean_summary_tokens=32, median_summary_tokens=34, mode_summary_tokens=35 \n",
      "max_tokens_cr = 75.61, min_tokens_cr = 21.67, mean_tokens_cr = 41.82, median_tokens_cr = 39.89, mode_tokens_cr = 21.67 \n",
      "In a bin out of 18 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_1 , bin_num = 30 , total_samples_in_a_bin = 144 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=208, min_article_tokens=26, mean_article_tokens=86, median_article_tokens=82, mode_article_tokens=65 \n",
      "max_summary_tokens=100, min_summary_tokens=14, mean_summary_tokens=37, median_summary_tokens=36, mode_summary_tokens=37 \n",
      "max_tokens_cr = 88.64, min_tokens_cr = 13.46, mean_tokens_cr = 46.20, median_tokens_cr = 45.85, mode_tokens_cr = 25.00 \n",
      "In a bin out of 144 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_1 , bin_num = 40 , total_samples_in_a_bin = 447 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=279, min_article_tokens=25, mean_article_tokens=92, median_article_tokens=86, mode_article_tokens=63 \n",
      "max_summary_tokens=111, min_summary_tokens=10, mean_summary_tokens=40, median_summary_tokens=37, mode_summary_tokens=36 \n",
      "max_tokens_cr = 90.77, min_tokens_cr = 7.17, mean_tokens_cr = 46.37, median_tokens_cr = 45.33, mode_tokens_cr = 50.00 \n",
      "In a bin out of 447 samples, 1  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_1 , bin_num = 50 , total_samples_in_a_bin = 1103 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=255, min_article_tokens=24, mean_article_tokens=94, median_article_tokens=89, mode_article_tokens=86 \n",
      "max_summary_tokens=116, min_summary_tokens=13, mean_summary_tokens=43, median_summary_tokens=40, mode_summary_tokens=35 \n",
      "max_tokens_cr = 97.18, min_tokens_cr = 11.17, mean_tokens_cr = 48.16, median_tokens_cr = 47.06, mode_tokens_cr = 50.00 \n",
      "In a bin out of 1103 samples, 7  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param = precision_copy_rouge_1 , bin_num = 60 , total_samples_in_a_bin = 1882 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=25, mean_article_tokens=97, median_article_tokens=94, mode_article_tokens=96 \n",
      "max_summary_tokens=168, min_summary_tokens=11, mean_summary_tokens=47, median_summary_tokens=44, mode_summary_tokens=39 \n",
      "max_tokens_cr = 98.28, min_tokens_cr = 8.81, mean_tokens_cr = 50.56, median_tokens_cr = 49.21, mode_tokens_cr = 40.00 \n",
      "In a bin out of 1882 samples, 18  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_1 , bin_num = 70 , total_samples_in_a_bin = 2976 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=258, min_article_tokens=22, mean_article_tokens=96, median_article_tokens=93, mode_article_tokens=85 \n",
      "max_summary_tokens=123, min_summary_tokens=8, mean_summary_tokens=48, median_summary_tokens=46, mode_summary_tokens=43 \n",
      "max_tokens_cr = 97.96, min_tokens_cr = 10.32, mean_tokens_cr = 52.90, median_tokens_cr = 52.45, mode_tokens_cr = 50.00 \n",
      "In a bin out of 2976 samples, 24  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_1 , bin_num = 80 , total_samples_in_a_bin = 5037 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=319, min_article_tokens=23, mean_article_tokens=92, median_article_tokens=89, mode_article_tokens=92 \n",
      "max_summary_tokens=159, min_summary_tokens=10, mean_summary_tokens=49, median_summary_tokens=47, mode_summary_tokens=44 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 4.39, mean_tokens_cr = 55.81, median_tokens_cr = 55.38, mode_tokens_cr = 50.00 \n",
      "In a bin out of 5037 samples, 52  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_1 , bin_num = 90 , total_samples_in_a_bin = 7309 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=302, min_article_tokens=22, mean_article_tokens=90, median_article_tokens=87, mode_article_tokens=91 \n",
      "max_summary_tokens=151, min_summary_tokens=11, mean_summary_tokens=51, median_summary_tokens=48, mode_summary_tokens=36 \n",
      "max_tokens_cr = 98.85, min_tokens_cr = 14.10, mean_tokens_cr = 58.44, median_tokens_cr = 57.97, mode_tokens_cr = 50.00 \n",
      "In a bin out of 7309 samples, 151  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_1 , bin_num = 100 , total_samples_in_a_bin = 7662 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=22, mean_article_tokens=90, median_article_tokens=86, mode_article_tokens=79 \n",
      "max_summary_tokens=329, min_summary_tokens=9, mean_summary_tokens=53, median_summary_tokens=49, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 6.50, mean_tokens_cr = 60.43, median_tokens_cr = 60.00, mode_tokens_cr = 50.00 \n",
      "In a bin out of 7662 samples, 294  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "======================================================= precision_copy_rouge_2 =================================================\n",
      "\n",
      "\n",
      "param = precision_copy_rouge_2 , bin_num = 10 , total_samples_in_a_bin = 314 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=241, min_article_tokens=25, mean_article_tokens=92, median_article_tokens=87, mode_article_tokens=72 \n",
      "max_summary_tokens=146, min_summary_tokens=13, mean_summary_tokens=37, median_summary_tokens=34, mode_summary_tokens=33 \n",
      "max_tokens_cr = 88.64, min_tokens_cr = 12.45, mean_tokens_cr = 43.55, median_tokens_cr = 41.63, mode_tokens_cr = 33.33 \n",
      "In a bin out of 314 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_2 , bin_num = 20 , total_samples_in_a_bin = 955 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=279, min_article_tokens=24, mean_article_tokens=95, median_article_tokens=89, mode_article_tokens=82 \n",
      "max_summary_tokens=123, min_summary_tokens=8, mean_summary_tokens=41, median_summary_tokens=39, mode_summary_tokens=31 \n",
      "max_tokens_cr = 92.11, min_tokens_cr = 7.17, mean_tokens_cr = 46.32, median_tokens_cr = 45.33, mode_tokens_cr = 40.00 \n",
      "In a bin out of 955 samples, 2  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_2 , bin_num = 30 , total_samples_in_a_bin = 1611 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=252, min_article_tokens=24, mean_article_tokens=96, median_article_tokens=92, mode_article_tokens=88 \n",
      "max_summary_tokens=168, min_summary_tokens=13, mean_summary_tokens=45, median_summary_tokens=42, mode_summary_tokens=39 \n",
      "max_tokens_cr = 97.40, min_tokens_cr = 10.32, mean_tokens_cr = 49.23, median_tokens_cr = 48.00, mode_tokens_cr = 50.00 \n",
      "In a bin out of 1611 samples, 10  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_2 , bin_num = 40 , total_samples_in_a_bin = 2345 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=25, mean_article_tokens=97, median_article_tokens=94, mode_article_tokens=101 \n",
      "max_summary_tokens=132, min_summary_tokens=11, mean_summary_tokens=47, median_summary_tokens=44, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.28, min_tokens_cr = 9.95, mean_tokens_cr = 50.99, median_tokens_cr = 50.48, mode_tokens_cr = 50.00 \n",
      "In a bin out of 2345 samples, 18  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_2 , bin_num = 50 , total_samples_in_a_bin = 3157 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=319, min_article_tokens=22, mean_article_tokens=93, median_article_tokens=89, mode_article_tokens=74 \n",
      "max_summary_tokens=155, min_summary_tokens=10, mean_summary_tokens=48, median_summary_tokens=46, mode_summary_tokens=47 \n",
      "max_tokens_cr = 97.96, min_tokens_cr = 5.19, mean_tokens_cr = 54.21, median_tokens_cr = 54.00, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3157 samples, 20  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_2 , bin_num = 60 , total_samples_in_a_bin = 3788 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=296, min_article_tokens=23, mean_article_tokens=90, median_article_tokens=88, mode_article_tokens=92 \n",
      "max_summary_tokens=159, min_summary_tokens=13, mean_summary_tokens=49, median_summary_tokens=46, mode_summary_tokens=38 \n",
      "max_tokens_cr = 99.02, min_tokens_cr = 4.39, mean_tokens_cr = 55.82, median_tokens_cr = 55.34, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3788 samples, 36  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_2 , bin_num = 70 , total_samples_in_a_bin = 4554 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=271, min_article_tokens=22, mean_article_tokens=89, median_article_tokens=87, mode_article_tokens=80 \n",
      "max_summary_tokens=134, min_summary_tokens=10, mean_summary_tokens=50, median_summary_tokens=47, mode_summary_tokens=39 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 13.51, mean_tokens_cr = 57.96, median_tokens_cr = 57.74, mode_tokens_cr = 50.00 \n",
      "In a bin out of 4554 samples, 64  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_2 , bin_num = 80 , total_samples_in_a_bin = 4630 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=302, min_article_tokens=25, mean_article_tokens=90, median_article_tokens=86, mode_article_tokens=77 \n",
      "max_summary_tokens=151, min_summary_tokens=13, mean_summary_tokens=52, median_summary_tokens=48, mode_summary_tokens=36 \n",
      "max_tokens_cr = 98.85, min_tokens_cr = 6.50, mean_tokens_cr = 59.60, median_tokens_cr = 59.14, mode_tokens_cr = 50.00 \n",
      "In a bin out of 4630 samples, 121  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_2 , bin_num = 90 , total_samples_in_a_bin = 3660 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=243, min_article_tokens=22, mean_article_tokens=91, median_article_tokens=86, mode_article_tokens=81 \n",
      "max_summary_tokens=187, min_summary_tokens=12, mean_summary_tokens=54, median_summary_tokens=51, mode_summary_tokens=48 \n",
      "max_tokens_cr = 98.65, min_tokens_cr = 13.28, mean_tokens_cr = 62.12, median_tokens_cr = 62.24, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3660 samples, 171  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_2 , bin_num = 100 , total_samples_in_a_bin = 1580 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=26, mean_article_tokens=98, median_article_tokens=90, mode_article_tokens=70 \n",
      "max_summary_tokens=329, min_summary_tokens=9, mean_summary_tokens=60, median_summary_tokens=55, mode_summary_tokens=45 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 11.72, mean_tokens_cr = 62.81, median_tokens_cr = 63.13, mode_tokens_cr = 66.67 \n",
      "In a bin out of 1580 samples, 105  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "======================================================= precision_copy_rouge_3 =================================================\n",
      "\n",
      "\n",
      "param = precision_copy_rouge_3 , bin_num = 10 , total_samples_in_a_bin = 1580 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=279, min_article_tokens=24, mean_article_tokens=92, median_article_tokens=88, mode_article_tokens=65 \n",
      "max_summary_tokens=146, min_summary_tokens=8, mean_summary_tokens=40, median_summary_tokens=37, mode_summary_tokens=33 \n",
      "max_tokens_cr = 95.65, min_tokens_cr = 7.17, mean_tokens_cr = 46.14, median_tokens_cr = 44.68, mode_tokens_cr = 40.00 \n",
      "In a bin out of 1580 samples, 4  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_3 , bin_num = 20 , total_samples_in_a_bin = 2333 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=238, min_article_tokens=23, mean_article_tokens=95, median_article_tokens=91, mode_article_tokens=83 \n",
      "max_summary_tokens=168, min_summary_tokens=14, mean_summary_tokens=45, median_summary_tokens=43, mode_summary_tokens=37 \n",
      "max_tokens_cr = 97.40, min_tokens_cr = 9.95, mean_tokens_cr = 50.00, median_tokens_cr = 49.15, mode_tokens_cr = 50.00 \n",
      "In a bin out of 2333 samples, 15  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param = precision_copy_rouge_3 , bin_num = 30 , total_samples_in_a_bin = 2931 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=24, mean_article_tokens=95, median_article_tokens=91, mode_article_tokens=101 \n",
      "max_summary_tokens=132, min_summary_tokens=10, mean_summary_tokens=47, median_summary_tokens=45, mode_summary_tokens=39 \n",
      "max_tokens_cr = 98.28, min_tokens_cr = 8.81, mean_tokens_cr = 52.58, median_tokens_cr = 52.11, mode_tokens_cr = 50.00 \n",
      "In a bin out of 2931 samples, 19  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_3 , bin_num = 40 , total_samples_in_a_bin = 3587 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=319, min_article_tokens=22, mean_article_tokens=91, median_article_tokens=88, mode_article_tokens=74 \n",
      "max_summary_tokens=134, min_summary_tokens=11, mean_summary_tokens=48, median_summary_tokens=46, mode_summary_tokens=38 \n",
      "max_tokens_cr = 98.48, min_tokens_cr = 4.39, mean_tokens_cr = 55.03, median_tokens_cr = 54.43, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3587 samples, 32  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_3 , bin_num = 50 , total_samples_in_a_bin = 3978 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=282, min_article_tokens=22, mean_article_tokens=90, median_article_tokens=87, mode_article_tokens=71 \n",
      "max_summary_tokens=159, min_summary_tokens=10, mean_summary_tokens=49, median_summary_tokens=46, mode_summary_tokens=41 \n",
      "max_tokens_cr = 99.02, min_tokens_cr = 12.50, mean_tokens_cr = 56.48, median_tokens_cr = 56.34, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3978 samples, 37  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_3 , bin_num = 60 , total_samples_in_a_bin = 3735 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=302, min_article_tokens=22, mean_article_tokens=90, median_article_tokens=86, mode_article_tokens=91 \n",
      "max_summary_tokens=132, min_summary_tokens=12, mean_summary_tokens=51, median_summary_tokens=48, mode_summary_tokens=44 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 15.65, mean_tokens_cr = 58.47, median_tokens_cr = 58.16, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3735 samples, 57  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_3 , bin_num = 70 , total_samples_in_a_bin = 3427 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=249, min_article_tokens=25, mean_article_tokens=90, median_article_tokens=86, mode_article_tokens=77 \n",
      "max_summary_tokens=151, min_summary_tokens=13, mean_summary_tokens=53, median_summary_tokens=49, mode_summary_tokens=45 \n",
      "max_tokens_cr = 98.85, min_tokens_cr = 6.50, mean_tokens_cr = 60.21, median_tokens_cr = 59.81, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3427 samples, 100  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_3 , bin_num = 80 , total_samples_in_a_bin = 2850 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=260, min_article_tokens=22, mean_article_tokens=91, median_article_tokens=87, mode_article_tokens=81 \n",
      "max_summary_tokens=174, min_summary_tokens=14, mean_summary_tokens=55, median_summary_tokens=52, mode_summary_tokens=46 \n",
      "max_tokens_cr = 98.65, min_tokens_cr = 9.92, mean_tokens_cr = 62.10, median_tokens_cr = 62.17, mode_tokens_cr = 50.00 \n",
      "In a bin out of 2850 samples, 135  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_3 , bin_num = 90 , total_samples_in_a_bin = 1553 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=287, min_article_tokens=26, mean_article_tokens=95, median_article_tokens=89, mode_article_tokens=74 \n",
      "max_summary_tokens=212, min_summary_tokens=11, mean_summary_tokens=59, median_summary_tokens=55, mode_summary_tokens=48 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 18.03, mean_tokens_cr = 64.32, median_tokens_cr = 64.37, mode_tokens_cr = 66.67 \n",
      "In a bin out of 1553 samples, 110  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_3 , bin_num = 100 , total_samples_in_a_bin = 620 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=33, mean_article_tokens=104, median_article_tokens=94, mode_article_tokens=79 \n",
      "max_summary_tokens=329, min_summary_tokens=9, mean_summary_tokens=63, median_summary_tokens=59, mode_summary_tokens=45 \n",
      "max_tokens_cr = 98.80, min_tokens_cr = 11.72, mean_tokens_cr = 62.18, median_tokens_cr = 62.50, mode_tokens_cr = 50.00 \n",
      "In a bin out of 620 samples, 38  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "======================================================= precision_copy_rouge_4 =================================================\n",
      "\n",
      "\n",
      "param = precision_copy_rouge_4 , bin_num = 10 , total_samples_in_a_bin = 3618 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=296, min_article_tokens=23, mean_article_tokens=92, median_article_tokens=88, mode_article_tokens=65 \n",
      "max_summary_tokens=168, min_summary_tokens=8, mean_summary_tokens=42, median_summary_tokens=39, mode_summary_tokens=37 \n",
      "max_tokens_cr = 97.40, min_tokens_cr = 4.39, mean_tokens_cr = 48.22, median_tokens_cr = 47.22, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3618 samples, 17  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_4 , bin_num = 20 , total_samples_in_a_bin = 3562 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=290, min_article_tokens=22, mean_article_tokens=94, median_article_tokens=90, mode_article_tokens=81 \n",
      "max_summary_tokens=132, min_summary_tokens=10, mean_summary_tokens=47, median_summary_tokens=45, mode_summary_tokens=38 \n",
      "max_tokens_cr = 98.28, min_tokens_cr = 5.19, mean_tokens_cr = 52.64, median_tokens_cr = 52.07, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3562 samples, 19  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_4 , bin_num = 30 , total_samples_in_a_bin = 3820 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=22, mean_article_tokens=91, median_article_tokens=89, mode_article_tokens=74 \n",
      "max_summary_tokens=134, min_summary_tokens=10, mean_summary_tokens=48, median_summary_tokens=46, mode_summary_tokens=42 \n",
      "max_tokens_cr = 98.48, min_tokens_cr = 11.71, mean_tokens_cr = 54.84, median_tokens_cr = 54.39, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3820 samples, 37  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_4 , bin_num = 40 , total_samples_in_a_bin = 3842 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=282, min_article_tokens=24, mean_article_tokens=90, median_article_tokens=87, mode_article_tokens=69 \n",
      "max_summary_tokens=159, min_summary_tokens=12, mean_summary_tokens=49, median_summary_tokens=47, mode_summary_tokens=39 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 15.65, mean_tokens_cr = 56.96, median_tokens_cr = 56.67, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3842 samples, 41  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_4 , bin_num = 50 , total_samples_in_a_bin = 3682 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=302, min_article_tokens=22, mean_article_tokens=89, median_article_tokens=86, mode_article_tokens=91 \n",
      "max_summary_tokens=131, min_summary_tokens=14, mean_summary_tokens=50, median_summary_tokens=48, mode_summary_tokens=40 \n",
      "max_tokens_cr = 98.08, min_tokens_cr = 6.50, mean_tokens_cr = 58.49, median_tokens_cr = 58.33, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3682 samples, 60  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_4 , bin_num = 60 , total_samples_in_a_bin = 2934 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=249, min_article_tokens=23, mean_article_tokens=92, median_article_tokens=87, mode_article_tokens=79 \n",
      "max_summary_tokens=151, min_summary_tokens=12, mean_summary_tokens=53, median_summary_tokens=50, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.85, min_tokens_cr = 14.29, mean_tokens_cr = 60.19, median_tokens_cr = 59.68, mode_tokens_cr = 50.00 \n",
      "In a bin out of 2934 samples, 73  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_4 , bin_num = 70 , total_samples_in_a_bin = 2429 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=260, min_article_tokens=26, mean_article_tokens=92, median_article_tokens=88, mode_article_tokens=68 \n",
      "max_summary_tokens=174, min_summary_tokens=14, mean_summary_tokens=55, median_summary_tokens=52, mode_summary_tokens=46 \n",
      "max_tokens_cr = 98.65, min_tokens_cr = 9.92, mean_tokens_cr = 62.17, median_tokens_cr = 62.50, mode_tokens_cr = 50.00 \n",
      "In a bin out of 2429 samples, 111  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_4 , bin_num = 80 , total_samples_in_a_bin = 1545 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=282, min_article_tokens=22, mean_article_tokens=94, median_article_tokens=90, mode_article_tokens=74 \n",
      "max_summary_tokens=163, min_summary_tokens=11, mean_summary_tokens=58, median_summary_tokens=55, mode_summary_tokens=50 \n",
      "max_tokens_cr = 98.48, min_tokens_cr = 18.03, mean_tokens_cr = 63.81, median_tokens_cr = 64.13, mode_tokens_cr = 66.67 \n",
      "In a bin out of 1545 samples, 95  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param = precision_copy_rouge_4 , bin_num = 90 , total_samples_in_a_bin = 824 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=299, min_article_tokens=33, mean_article_tokens=100, median_article_tokens=91, mode_article_tokens=88 \n",
      "max_summary_tokens=272, min_summary_tokens=13, mean_summary_tokens=62, median_summary_tokens=58, mode_summary_tokens=45 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 16.48, mean_tokens_cr = 63.74, median_tokens_cr = 63.75, mode_tokens_cr = 50.00 \n",
      "In a bin out of 824 samples, 73  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_4 , bin_num = 100 , total_samples_in_a_bin = 338 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=38, mean_article_tokens=104, median_article_tokens=96, mode_article_tokens=85 \n",
      "max_summary_tokens=329, min_summary_tokens=9, mean_summary_tokens=66, median_summary_tokens=60, mode_summary_tokens=66 \n",
      "max_tokens_cr = 98.80, min_tokens_cr = 11.72, mean_tokens_cr = 63.67, median_tokens_cr = 65.17, mode_tokens_cr = 53.23 \n",
      "In a bin out of 338 samples, 21  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "======================================================= precision_copy_rouge_L =================================================\n",
      "\n",
      "\n",
      "param = precision_copy_rouge_L , bin_num = 10 , total_samples_in_a_bin = 18 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=211, min_article_tokens=46, mean_article_tokens=106, median_article_tokens=92, mode_article_tokens=46 \n",
      "max_summary_tokens=146, min_summary_tokens=23, mean_summary_tokens=51, median_summary_tokens=42, mode_summary_tokens=35 \n",
      "max_tokens_cr = 81.72, min_tokens_cr = 19.43, mean_tokens_cr = 52.09, median_tokens_cr = 52.28, mode_tokens_cr = 19.43 \n",
      "In a bin out of 18 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_L , bin_num = 20 , total_samples_in_a_bin = 120 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=237, min_article_tokens=27, mean_article_tokens=94, median_article_tokens=89, mode_article_tokens=65 \n",
      "max_summary_tokens=100, min_summary_tokens=16, mean_summary_tokens=39, median_summary_tokens=37, mode_summary_tokens=35 \n",
      "max_tokens_cr = 86.84, min_tokens_cr = 14.77, mean_tokens_cr = 44.85, median_tokens_cr = 44.55, mode_tokens_cr = 32.46 \n",
      "In a bin out of 120 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_L , bin_num = 30 , total_samples_in_a_bin = 681 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=279, min_article_tokens=26, mean_article_tokens=93, median_article_tokens=89, mode_article_tokens=86 \n",
      "max_summary_tokens=111, min_summary_tokens=14, mean_summary_tokens=42, median_summary_tokens=40, mode_summary_tokens=37 \n",
      "max_tokens_cr = 89.66, min_tokens_cr = 7.17, mean_tokens_cr = 48.22, median_tokens_cr = 47.67, mode_tokens_cr = 50.00 \n",
      "In a bin out of 681 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_L , bin_num = 40 , total_samples_in_a_bin = 1840 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=319, min_article_tokens=23, mean_article_tokens=94, median_article_tokens=90, mode_article_tokens=98 \n",
      "max_summary_tokens=123, min_summary_tokens=8, mean_summary_tokens=45, median_summary_tokens=43, mode_summary_tokens=43 \n",
      "max_tokens_cr = 95.69, min_tokens_cr = 10.46, mean_tokens_cr = 49.92, median_tokens_cr = 49.33, mode_tokens_cr = 50.00 \n",
      "In a bin out of 1840 samples, 10  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_L , bin_num = 50 , total_samples_in_a_bin = 3431 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=24, mean_article_tokens=93, median_article_tokens=90, mode_article_tokens=76 \n",
      "max_summary_tokens=168, min_summary_tokens=10, mean_summary_tokens=47, median_summary_tokens=45, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.48, min_tokens_cr = 10.97, mean_tokens_cr = 53.27, median_tokens_cr = 52.83, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3431 samples, 31  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_L , bin_num = 60 , total_samples_in_a_bin = 4380 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=296, min_article_tokens=26, mean_article_tokens=93, median_article_tokens=90, mode_article_tokens=77 \n",
      "max_summary_tokens=155, min_summary_tokens=11, mean_summary_tokens=49, median_summary_tokens=47, mode_summary_tokens=37 \n",
      "max_tokens_cr = 98.48, min_tokens_cr = 4.39, mean_tokens_cr = 55.31, median_tokens_cr = 54.89, mode_tokens_cr = 50.00 \n",
      "In a bin out of 4380 samples, 48  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_L , bin_num = 70 , total_samples_in_a_bin = 4994 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=289, min_article_tokens=22, mean_article_tokens=91, median_article_tokens=88, mode_article_tokens=73 \n",
      "max_summary_tokens=159, min_summary_tokens=11, mean_summary_tokens=50, median_summary_tokens=47, mode_summary_tokens=38 \n",
      "max_tokens_cr = 98.73, min_tokens_cr = 5.19, mean_tokens_cr = 57.09, median_tokens_cr = 56.96, mode_tokens_cr = 50.00 \n",
      "In a bin out of 4994 samples, 77  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_L , bin_num = 80 , total_samples_in_a_bin = 4822 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=249, min_article_tokens=23, mean_article_tokens=90, median_article_tokens=87, mode_article_tokens=78 \n",
      "max_summary_tokens=212, min_summary_tokens=10, mean_summary_tokens=51, median_summary_tokens=48, mode_summary_tokens=45 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 13.51, mean_tokens_cr = 58.72, median_tokens_cr = 58.16, mode_tokens_cr = 50.00 \n",
      "In a bin out of 4822 samples, 116  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_L , bin_num = 90 , total_samples_in_a_bin = 3685 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=302, min_article_tokens=22, mean_article_tokens=91, median_article_tokens=87, mode_article_tokens=68 \n",
      "max_summary_tokens=187, min_summary_tokens=13, mean_summary_tokens=53, median_summary_tokens=49, mode_summary_tokens=46 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 9.92, mean_tokens_cr = 60.11, median_tokens_cr = 59.81, mode_tokens_cr = 50.00 \n",
      "In a bin out of 3685 samples, 129  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = precision_copy_rouge_L , bin_num = 100 , total_samples_in_a_bin = 2623 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=22, mean_article_tokens=93, median_article_tokens=86, mode_article_tokens=70 \n",
      "max_summary_tokens=329, min_summary_tokens=9, mean_summary_tokens=55, median_summary_tokens=51, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.80, min_tokens_cr = 6.50, mean_tokens_cr = 61.05, median_tokens_cr = 60.81, mode_tokens_cr = 66.67 \n",
      "In a bin out of 2623 samples, 136  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "******************************************************** copy_recall **********************************************************\n",
      "\n",
      "\n",
      "======================================================= recall_copy_rouge_1 =================================================\n",
      "\n",
      "\n",
      "param = recall_copy_rouge_1 , bin_num = 10 , total_samples_in_a_bin = 225 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=296, min_article_tokens=46, mean_article_tokens=137, median_article_tokens=132, mode_article_tokens=119 \n",
      "max_summary_tokens=146, min_summary_tokens=8, mean_summary_tokens=29, median_summary_tokens=28, mode_summary_tokens=20 \n",
      "max_tokens_cr = 81.72, min_tokens_cr = 4.39, mean_tokens_cr = 24.42, median_tokens_cr = 21.89, mode_tokens_cr = 25.00 \n",
      "In a bin out of 225 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_1 , bin_num = 20 , total_samples_in_a_bin = 1500 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=32, mean_article_tokens=110, median_article_tokens=106, mode_article_tokens=99 \n",
      "max_summary_tokens=100, min_summary_tokens=9, mean_summary_tokens=35, median_summary_tokens=34, mode_summary_tokens=37 \n",
      "max_tokens_cr = 86.84, min_tokens_cr = 11.72, mean_tokens_cr = 33.57, median_tokens_cr = 32.39, mode_tokens_cr = 33.33 \n",
      "In a bin out of 1500 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_1 , bin_num = 30 , total_samples_in_a_bin = 3422 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=319, min_article_tokens=25, mean_article_tokens=102, median_article_tokens=99, mode_article_tokens=90 \n",
      "max_summary_tokens=120, min_summary_tokens=11, mean_summary_tokens=40, median_summary_tokens=39, mode_summary_tokens=36 \n",
      "max_tokens_cr = 88.64, min_tokens_cr = 20.35, mean_tokens_cr = 40.91, median_tokens_cr = 39.19, mode_tokens_cr = 33.33 \n",
      "In a bin out of 3422 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param = recall_copy_rouge_1 , bin_num = 40 , total_samples_in_a_bin = 5444 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=282, min_article_tokens=24, mean_article_tokens=97, median_article_tokens=94, mode_article_tokens=91 \n",
      "max_summary_tokens=155, min_summary_tokens=12, mean_summary_tokens=46, median_summary_tokens=44, mode_summary_tokens=38 \n",
      "max_tokens_cr = 90.77, min_tokens_cr = 30.23, mean_tokens_cr = 47.94, median_tokens_cr = 46.28, mode_tokens_cr = 50.00 \n",
      "In a bin out of 5444 samples, 2  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_1 , bin_num = 50 , total_samples_in_a_bin = 6020 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=293, min_article_tokens=23, mean_article_tokens=90, median_article_tokens=87, mode_article_tokens=88 \n",
      "max_summary_tokens=168, min_summary_tokens=13, mean_summary_tokens=50, median_summary_tokens=48, mode_summary_tokens=44 \n",
      "max_tokens_cr = 97.18, min_tokens_cr = 40.16, mean_tokens_cr = 55.97, median_tokens_cr = 54.58, mode_tokens_cr = 50.00 \n",
      "In a bin out of 6020 samples, 7  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_1 , bin_num = 60 , total_samples_in_a_bin = 4679 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=330, min_article_tokens=23, mean_article_tokens=86, median_article_tokens=82, mode_article_tokens=62 \n",
      "max_summary_tokens=193, min_summary_tokens=14, mean_summary_tokens=55, median_summary_tokens=53, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.28, min_tokens_cr = 50.39, mean_tokens_cr = 64.46, median_tokens_cr = 63.33, mode_tokens_cr = 66.67 \n",
      "In a bin out of 4679 samples, 26  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_1 , bin_num = 70 , total_samples_in_a_bin = 3049 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=287, min_article_tokens=22, mean_article_tokens=82, median_article_tokens=79, mode_article_tokens=78 \n",
      "max_summary_tokens=189, min_summary_tokens=16, mean_summary_tokens=59, median_summary_tokens=57, mode_summary_tokens=50 \n",
      "max_tokens_cr = 97.96, min_tokens_cr = 60.29, mean_tokens_cr = 72.52, median_tokens_cr = 71.62, mode_tokens_cr = 66.67 \n",
      "In a bin out of 3049 samples, 32  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_1 , bin_num = 80 , total_samples_in_a_bin = 1542 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=201, min_article_tokens=22, mean_article_tokens=78, median_article_tokens=74, mode_article_tokens=68 \n",
      "max_summary_tokens=158, min_summary_tokens=17, mean_summary_tokens=63, median_summary_tokens=60, mode_summary_tokens=61 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 70.06, mean_tokens_cr = 81.03, median_tokens_cr = 80.50, mode_tokens_cr = 80.00 \n",
      "In a bin out of 1542 samples, 107  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_1 , bin_num = 90 , total_samples_in_a_bin = 610 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=23, mean_article_tokens=78, median_article_tokens=71, mode_article_tokens=71 \n",
      "max_summary_tokens=329, min_summary_tokens=20, mean_summary_tokens=69, median_summary_tokens=65, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.85, min_tokens_cr = 80.43, mean_tokens_cr = 89.52, median_tokens_cr = 89.39, mode_tokens_cr = 87.50 \n",
      "In a bin out of 610 samples, 270  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_1 , bin_num = 100 , total_samples_in_a_bin = 103 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=222, min_article_tokens=34, mean_article_tokens=82, median_article_tokens=75, mode_article_tokens=53 \n",
      "max_summary_tokens=212, min_summary_tokens=31, mean_summary_tokens=79, median_summary_tokens=72, mode_summary_tokens=69 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 90.14, mean_tokens_cr = 95.63, median_tokens_cr = 95.83, mode_tokens_cr = 95.83 \n",
      "In a bin out of 103 samples, 103  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "======================================================= recall_copy_rouge_2 =================================================\n",
      "\n",
      "\n",
      "param = recall_copy_rouge_2 , bin_num = 10 , total_samples_in_a_bin = 1861 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=25, mean_article_tokens=105, median_article_tokens=100, mode_article_tokens=82 \n",
      "max_summary_tokens=146, min_summary_tokens=8, mean_summary_tokens=36, median_summary_tokens=35, mode_summary_tokens=37 \n",
      "max_tokens_cr = 89.69, min_tokens_cr = 4.39, mean_tokens_cr = 37.38, median_tokens_cr = 36.21, mode_tokens_cr = 40.00 \n",
      "In a bin out of 1861 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_2 , bin_num = 20 , total_samples_in_a_bin = 4011 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=319, min_article_tokens=24, mean_article_tokens=100, median_article_tokens=97, mode_article_tokens=81 \n",
      "max_summary_tokens=125, min_summary_tokens=9, mean_summary_tokens=43, median_summary_tokens=41, mode_summary_tokens=43 \n",
      "max_tokens_cr = 92.11, min_tokens_cr = 11.72, mean_tokens_cr = 44.38, median_tokens_cr = 43.04, mode_tokens_cr = 50.00 \n",
      "In a bin out of 4011 samples, 3  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_2 , bin_num = 30 , total_samples_in_a_bin = 5588 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=302, min_article_tokens=24, mean_article_tokens=95, median_article_tokens=92, mode_article_tokens=75 \n",
      "max_summary_tokens=168, min_summary_tokens=12, mean_summary_tokens=46, median_summary_tokens=44, mode_summary_tokens=44 \n",
      "max_tokens_cr = 97.40, min_tokens_cr = 22.02, mean_tokens_cr = 49.69, median_tokens_cr = 48.43, mode_tokens_cr = 50.00 \n",
      "In a bin out of 5588 samples, 13  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_2 , bin_num = 40 , total_samples_in_a_bin = 5665 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=282, min_article_tokens=23, mean_article_tokens=90, median_article_tokens=87, mode_article_tokens=81 \n",
      "max_summary_tokens=159, min_summary_tokens=13, mean_summary_tokens=50, median_summary_tokens=47, mode_summary_tokens=38 \n",
      "max_tokens_cr = 98.28, min_tokens_cr = 32.50, mean_tokens_cr = 56.16, median_tokens_cr = 55.10, mode_tokens_cr = 50.00 \n",
      "In a bin out of 5665 samples, 18  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_2 , bin_num = 50 , total_samples_in_a_bin = 4380 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=293, min_article_tokens=22, mean_article_tokens=87, median_article_tokens=84, mode_article_tokens=85 \n",
      "max_summary_tokens=139, min_summary_tokens=14, mean_summary_tokens=54, median_summary_tokens=52, mode_summary_tokens=44 \n",
      "max_tokens_cr = 97.96, min_tokens_cr = 41.38, mean_tokens_cr = 63.40, median_tokens_cr = 62.50, mode_tokens_cr = 66.67 \n",
      "In a bin out of 4380 samples, 28  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_2 , bin_num = 60 , total_samples_in_a_bin = 2702 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=330, min_article_tokens=25, mean_article_tokens=84, median_article_tokens=80, mode_article_tokens=78 \n",
      "max_summary_tokens=193, min_summary_tokens=18, mean_summary_tokens=58, median_summary_tokens=56, mode_summary_tokens=47 \n",
      "max_tokens_cr = 99.02, min_tokens_cr = 50.96, mean_tokens_cr = 70.35, median_tokens_cr = 69.42, mode_tokens_cr = 66.67 \n",
      "In a bin out of 2702 samples, 49  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_2 , bin_num = 70 , total_samples_in_a_bin = 1465 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=287, min_article_tokens=22, mean_article_tokens=81, median_article_tokens=78, mode_article_tokens=69 \n",
      "max_summary_tokens=189, min_summary_tokens=17, mean_summary_tokens=63, median_summary_tokens=60, mode_summary_tokens=61 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 61.18, mean_tokens_cr = 77.93, median_tokens_cr = 77.46, mode_tokens_cr = 75.00 \n",
      "In a bin out of 1465 samples, 88  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_2 , bin_num = 80 , total_samples_in_a_bin = 698 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=208, min_article_tokens=23, mean_article_tokens=82, median_article_tokens=77, mode_article_tokens=68 \n",
      "max_summary_tokens=187, min_summary_tokens=20, mean_summary_tokens=70, median_summary_tokens=65, mode_summary_tokens=60 \n",
      "max_tokens_cr = 98.85, min_tokens_cr = 70.25, mean_tokens_cr = 85.64, median_tokens_cr = 85.71, mode_tokens_cr = 81.82 \n",
      "In a bin out of 698 samples, 174  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_2 , bin_num = 90 , total_samples_in_a_bin = 191 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=33, mean_article_tokens=85, median_article_tokens=76, mode_article_tokens=53 \n",
      "max_summary_tokens=329, min_summary_tokens=28, mean_summary_tokens=78, median_summary_tokens=71, mode_summary_tokens=74 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 80.43, mean_tokens_cr = 92.09, median_tokens_cr = 92.77, mode_tokens_cr = 95.83 \n",
      "In a bin out of 191 samples, 141  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_2 , bin_num = 100 , total_samples_in_a_bin = 33 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=163, min_article_tokens=43, mean_article_tokens=86, median_article_tokens=77, mode_article_tokens=70 \n",
      "max_summary_tokens=152, min_summary_tokens=42, mean_summary_tokens=83, median_summary_tokens=75, mode_summary_tokens=69 \n",
      "max_tokens_cr = 98.80, min_tokens_cr = 91.04, mean_tokens_cr = 96.57, median_tokens_cr = 97.06, mode_tokens_cr = 98.57 \n",
      "In a bin out of 33 samples, 33  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "======================================================= recall_copy_rouge_3 =================================================\n",
      "\n",
      "\n",
      "param = recall_copy_rouge_3 , bin_num = 10 , total_samples_in_a_bin = 4442 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=23, mean_article_tokens=99, median_article_tokens=96, mode_article_tokens=96 \n",
      "max_summary_tokens=146, min_summary_tokens=8, mean_summary_tokens=40, median_summary_tokens=38, mode_summary_tokens=37 \n",
      "max_tokens_cr = 95.69, min_tokens_cr = 4.39, mean_tokens_cr = 43.01, median_tokens_cr = 41.56, mode_tokens_cr = 50.00 \n",
      "In a bin out of 4442 samples, 5  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param = recall_copy_rouge_3 , bin_num = 20 , total_samples_in_a_bin = 5798 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=319, min_article_tokens=24, mean_article_tokens=95, median_article_tokens=92, mode_article_tokens=81 \n",
      "max_summary_tokens=168, min_summary_tokens=11, mean_summary_tokens=45, median_summary_tokens=43, mode_summary_tokens=38 \n",
      "max_tokens_cr = 97.40, min_tokens_cr = 11.72, mean_tokens_cr = 49.40, median_tokens_cr = 48.43, mode_tokens_cr = 50.00 \n",
      "In a bin out of 5798 samples, 16  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_3 , bin_num = 30 , total_samples_in_a_bin = 5908 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=290, min_article_tokens=22, mean_article_tokens=92, median_article_tokens=89, mode_article_tokens=74 \n",
      "max_summary_tokens=159, min_summary_tokens=13, mean_summary_tokens=49, median_summary_tokens=47, mode_summary_tokens=43 \n",
      "max_tokens_cr = 98.28, min_tokens_cr = 22.02, mean_tokens_cr = 54.67, median_tokens_cr = 53.98, mode_tokens_cr = 50.00 \n",
      "In a bin out of 5908 samples, 21  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_3 , bin_num = 40 , total_samples_in_a_bin = 4564 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=282, min_article_tokens=22, mean_article_tokens=89, median_article_tokens=85, mode_article_tokens=85 \n",
      "max_summary_tokens=137, min_summary_tokens=14, mean_summary_tokens=52, median_summary_tokens=50, mode_summary_tokens=38 \n",
      "max_tokens_cr = 98.48, min_tokens_cr = 33.73, mean_tokens_cr = 60.65, median_tokens_cr = 59.81, mode_tokens_cr = 50.00 \n",
      "In a bin out of 4564 samples, 32  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_3 , bin_num = 50 , total_samples_in_a_bin = 2946 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=293, min_article_tokens=23, mean_article_tokens=86, median_article_tokens=81, mode_article_tokens=53 \n",
      "max_summary_tokens=154, min_summary_tokens=17, mean_summary_tokens=57, median_summary_tokens=54, mode_summary_tokens=50 \n",
      "max_tokens_cr = 99.02, min_tokens_cr = 43.04, mean_tokens_cr = 67.51, median_tokens_cr = 66.67, mode_tokens_cr = 66.67 \n",
      "In a bin out of 2946 samples, 51  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_3 , bin_num = 60 , total_samples_in_a_bin = 1647 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=330, min_article_tokens=22, mean_article_tokens=85, median_article_tokens=81, mode_article_tokens=57 \n",
      "max_summary_tokens=193, min_summary_tokens=17, mean_summary_tokens=62, median_summary_tokens=60, mode_summary_tokens=53 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 50.96, mean_tokens_cr = 73.98, median_tokens_cr = 73.68, mode_tokens_cr = 66.67 \n",
      "In a bin out of 1647 samples, 74  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_3 , bin_num = 70 , total_samples_in_a_bin = 825 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=233, min_article_tokens=23, mean_article_tokens=84, median_article_tokens=80, mode_article_tokens=68 \n",
      "max_summary_tokens=174, min_summary_tokens=20, mean_summary_tokens=67, median_summary_tokens=64, mode_summary_tokens=48 \n",
      "max_tokens_cr = 98.85, min_tokens_cr = 61.18, mean_tokens_cr = 80.78, median_tokens_cr = 80.33, mode_tokens_cr = 75.00 \n",
      "In a bin out of 825 samples, 118  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_3 , bin_num = 80 , total_samples_in_a_bin = 354 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=208, min_article_tokens=26, mean_article_tokens=84, median_article_tokens=77, mode_article_tokens=74 \n",
      "max_summary_tokens=187, min_summary_tokens=22, mean_summary_tokens=73, median_summary_tokens=68, mode_summary_tokens=66 \n",
      "max_tokens_cr = 98.65, min_tokens_cr = 71.95, mean_tokens_cr = 87.38, median_tokens_cr = 88.00, mode_tokens_cr = 90.00 \n",
      "In a bin out of 354 samples, 140  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_3 , bin_num = 90 , total_samples_in_a_bin = 98 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=39, mean_article_tokens=94, median_article_tokens=80, mode_article_tokens=70 \n",
      "max_summary_tokens=329, min_summary_tokens=33, mean_summary_tokens=88, median_summary_tokens=74, mode_summary_tokens=69 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 84.62, mean_tokens_cr = 93.72, median_tokens_cr = 94.71, mode_tokens_cr = 95.83 \n",
      "In a bin out of 98 samples, 78  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_3 , bin_num = 100 , total_samples_in_a_bin = 12 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=163, min_article_tokens=48, mean_article_tokens=100, median_article_tokens=99, mode_article_tokens=48 \n",
      "max_summary_tokens=152, min_summary_tokens=44, mean_summary_tokens=95, median_summary_tokens=94, mode_summary_tokens=82 \n",
      "max_tokens_cr = 98.80, min_tokens_cr = 91.04, mean_tokens_cr = 95.34, median_tokens_cr = 95.98, mode_tokens_cr = 91.04 \n",
      "In a bin out of 12 samples, 12  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "======================================================= recall_copy_rouge_4 =================================================\n",
      "\n",
      "\n",
      "param = recall_copy_rouge_4 , bin_num = 10 , total_samples_in_a_bin = 7485 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=23, mean_article_tokens=96, median_article_tokens=93, mode_article_tokens=81 \n",
      "max_summary_tokens=168, min_summary_tokens=8, mean_summary_tokens=42, median_summary_tokens=40, mode_summary_tokens=37 \n",
      "max_tokens_cr = 97.40, min_tokens_cr = 4.39, mean_tokens_cr = 46.18, median_tokens_cr = 45.24, mode_tokens_cr = 50.00 \n",
      "In a bin out of 7485 samples, 18  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_4 , bin_num = 20 , total_samples_in_a_bin = 6656 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=302, min_article_tokens=22, mean_article_tokens=92, median_article_tokens=90, mode_article_tokens=74 \n",
      "max_summary_tokens=159, min_summary_tokens=11, mean_summary_tokens=47, median_summary_tokens=45, mode_summary_tokens=43 \n",
      "max_tokens_cr = 98.28, min_tokens_cr = 16.42, mean_tokens_cr = 52.88, median_tokens_cr = 52.17, mode_tokens_cr = 50.00 \n",
      "In a bin out of 6656 samples, 22  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_4 , bin_num = 30 , total_samples_in_a_bin = 5206 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=290, min_article_tokens=22, mean_article_tokens=91, median_article_tokens=87, mode_article_tokens=81 \n",
      "max_summary_tokens=155, min_summary_tokens=13, mean_summary_tokens=51, median_summary_tokens=49, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.48, min_tokens_cr = 24.07, mean_tokens_cr = 58.09, median_tokens_cr = 57.33, mode_tokens_cr = 50.00 \n",
      "In a bin out of 5206 samples, 41  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_4 , bin_num = 40 , total_samples_in_a_bin = 3401 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=249, min_article_tokens=23, mean_article_tokens=89, median_article_tokens=85, mode_article_tokens=85 \n",
      "max_summary_tokens=140, min_summary_tokens=17, mean_summary_tokens=55, median_summary_tokens=53, mode_summary_tokens=50 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 33.87, mean_tokens_cr = 64.04, median_tokens_cr = 63.79, mode_tokens_cr = 66.67 \n",
      "In a bin out of 3401 samples, 47  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_4 , bin_num = 50 , total_samples_in_a_bin = 2032 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=293, min_article_tokens=22, mean_article_tokens=87, median_article_tokens=83, mode_article_tokens=70 \n",
      "max_summary_tokens=154, min_summary_tokens=18, mean_summary_tokens=60, median_summary_tokens=57, mode_summary_tokens=55 \n",
      "max_tokens_cr = 98.08, min_tokens_cr = 44.52, mean_tokens_cr = 70.40, median_tokens_cr = 69.53, mode_tokens_cr = 66.67 \n",
      "In a bin out of 2032 samples, 73  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_4 , bin_num = 60 , total_samples_in_a_bin = 1036 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=330, min_article_tokens=22, mean_article_tokens=87, median_article_tokens=81, mode_article_tokens=74 \n",
      "max_summary_tokens=193, min_summary_tokens=17, mean_summary_tokens=65, median_summary_tokens=61, mode_summary_tokens=48 \n",
      "max_tokens_cr = 98.85, min_tokens_cr = 53.23, mean_tokens_cr = 76.28, median_tokens_cr = 76.68, mode_tokens_cr = 71.43 \n",
      "In a bin out of 1036 samples, 89  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_4 , bin_num = 70 , total_samples_in_a_bin = 521 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=201, min_article_tokens=26, mean_article_tokens=87, median_article_tokens=81, mode_article_tokens=71 \n",
      "max_summary_tokens=174, min_summary_tokens=22, mean_summary_tokens=71, median_summary_tokens=67, mode_summary_tokens=53 \n",
      "max_tokens_cr = 98.65, min_tokens_cr = 62.14, mean_tokens_cr = 82.42, median_tokens_cr = 82.46, mode_tokens_cr = 81.82 \n",
      "In a bin out of 521 samples, 123  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_4 , bin_num = 80 , total_samples_in_a_bin = 197 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=222, min_article_tokens=33, mean_article_tokens=92, median_article_tokens=84, mode_article_tokens=70 \n",
      "max_summary_tokens=212, min_summary_tokens=28, mean_summary_tokens=81, median_summary_tokens=74, mode_summary_tokens=66 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 71.95, mean_tokens_cr = 87.92, median_tokens_cr = 88.57, mode_tokens_cr = 80.00 \n",
      "In a bin out of 197 samples, 85  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_4 , bin_num = 90 , total_samples_in_a_bin = 53 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=39, mean_article_tokens=95, median_article_tokens=80, mode_article_tokens=70 \n",
      "max_summary_tokens=329, min_summary_tokens=33, mean_summary_tokens=89, median_summary_tokens=74, mode_summary_tokens=105 \n",
      "max_tokens_cr = 98.65, min_tokens_cr = 84.62, mean_tokens_cr = 93.87, median_tokens_cr = 94.74, mode_tokens_cr = 98.57 \n",
      "In a bin out of 53 samples, 42  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_4 , bin_num = 100 , total_samples_in_a_bin = 7 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=163, min_article_tokens=48, mean_article_tokens=105, median_article_tokens=89, mode_article_tokens=48 \n",
      "max_summary_tokens=152, min_summary_tokens=44, mean_summary_tokens=99, median_summary_tokens=84, mode_summary_tokens=82 \n",
      "max_tokens_cr = 98.80, min_tokens_cr = 91.04, mean_tokens_cr = 94.63, median_tokens_cr = 94.38, mode_tokens_cr = 91.04 \n",
      "In a bin out of 7 samples, 7  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "======================================================= recall_copy_rouge_L =================================================\n",
      "\n",
      "\n",
      "param = recall_copy_rouge_L , bin_num = 10 , total_samples_in_a_bin = 562 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=38, mean_article_tokens=124, median_article_tokens=117, mode_article_tokens=134 \n",
      "max_summary_tokens=146, min_summary_tokens=8, mean_summary_tokens=32, median_summary_tokens=31, mode_summary_tokens=37 \n",
      "max_tokens_cr = 81.72, min_tokens_cr = 4.39, mean_tokens_cr = 28.48, median_tokens_cr = 26.93, mode_tokens_cr = 25.00 \n",
      "In a bin out of 562 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param = recall_copy_rouge_L , bin_num = 20 , total_samples_in_a_bin = 3288 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=319, min_article_tokens=27, mean_article_tokens=103, median_article_tokens=99, mode_article_tokens=81 \n",
      "max_summary_tokens=120, min_summary_tokens=9, mean_summary_tokens=39, median_summary_tokens=38, mode_summary_tokens=37 \n",
      "max_tokens_cr = 86.84, min_tokens_cr = 11.72, mean_tokens_cr = 39.67, median_tokens_cr = 38.32, mode_tokens_cr = 33.33 \n",
      "In a bin out of 3288 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_L , bin_num = 30 , total_samples_in_a_bin = 5700 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=302, min_article_tokens=23, mean_article_tokens=97, median_article_tokens=94, mode_article_tokens=101 \n",
      "max_summary_tokens=124, min_summary_tokens=11, mean_summary_tokens=45, median_summary_tokens=43, mode_summary_tokens=45 \n",
      "max_tokens_cr = 90.32, min_tokens_cr = 21.50, mean_tokens_cr = 47.89, median_tokens_cr = 46.77, mode_tokens_cr = 50.00 \n",
      "In a bin out of 5700 samples, 1  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_L , bin_num = 40 , total_samples_in_a_bin = 6448 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=282, min_article_tokens=23, mean_article_tokens=92, median_article_tokens=88, mode_article_tokens=73 \n",
      "max_summary_tokens=168, min_summary_tokens=12, mean_summary_tokens=50, median_summary_tokens=47, mode_summary_tokens=44 \n",
      "max_tokens_cr = 96.43, min_tokens_cr = 30.23, mean_tokens_cr = 55.16, median_tokens_cr = 54.29, mode_tokens_cr = 50.00 \n",
      "In a bin out of 6448 samples, 15  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_L , bin_num = 50 , total_samples_in_a_bin = 4894 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=293, min_article_tokens=23, mean_article_tokens=86, median_article_tokens=83, mode_article_tokens=62 \n",
      "max_summary_tokens=141, min_summary_tokens=13, mean_summary_tokens=53, median_summary_tokens=50, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.48, min_tokens_cr = 40.16, mean_tokens_cr = 62.63, median_tokens_cr = 61.75, mode_tokens_cr = 50.00 \n",
      "In a bin out of 4894 samples, 47  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_L , bin_num = 60 , total_samples_in_a_bin = 3039 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=330, min_article_tokens=23, mean_article_tokens=84, median_article_tokens=81, mode_article_tokens=81 \n",
      "max_summary_tokens=193, min_summary_tokens=16, mean_summary_tokens=58, median_summary_tokens=55, mode_summary_tokens=55 \n",
      "max_tokens_cr = 98.48, min_tokens_cr = 50.85, mean_tokens_cr = 69.48, median_tokens_cr = 68.66, mode_tokens_cr = 66.67 \n",
      "In a bin out of 3039 samples, 57  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_L , bin_num = 70 , total_samples_in_a_bin = 1565 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=287, min_article_tokens=22, mean_article_tokens=82, median_article_tokens=78, mode_article_tokens=78 \n",
      "max_summary_tokens=189, min_summary_tokens=16, mean_summary_tokens=62, median_summary_tokens=59, mode_summary_tokens=53 \n",
      "max_tokens_cr = 98.73, min_tokens_cr = 60.29, mean_tokens_cr = 76.14, median_tokens_cr = 75.61, mode_tokens_cr = 66.67 \n",
      "In a bin out of 1565 samples, 95  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_L , bin_num = 80 , total_samples_in_a_bin = 769 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=222, min_article_tokens=22, mean_article_tokens=80, median_article_tokens=75, mode_article_tokens=69 \n",
      "max_summary_tokens=212, min_summary_tokens=17, mean_summary_tokens=66, median_summary_tokens=62, mode_summary_tokens=45 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 70.06, mean_tokens_cr = 83.24, median_tokens_cr = 82.79, mode_tokens_cr = 83.33 \n",
      "In a bin out of 769 samples, 134  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_L , bin_num = 90 , total_samples_in_a_bin = 282 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=26, mean_article_tokens=79, median_article_tokens=71, mode_article_tokens=68 \n",
      "max_summary_tokens=329, min_summary_tokens=22, mean_summary_tokens=71, median_summary_tokens=65, mode_summary_tokens=66 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 80.43, mean_tokens_cr = 90.35, median_tokens_cr = 90.48, mode_tokens_cr = 88.89 \n",
      "In a bin out of 282 samples, 151  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = recall_copy_rouge_L , bin_num = 100 , total_samples_in_a_bin = 47 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=165, min_article_tokens=43, mean_article_tokens=86, median_article_tokens=81, mode_article_tokens=70 \n",
      "max_summary_tokens=154, min_summary_tokens=41, mean_summary_tokens=82, median_summary_tokens=75, mode_summary_tokens=69 \n",
      "max_tokens_cr = 98.80, min_tokens_cr = 90.14, mean_tokens_cr = 95.69, median_tokens_cr = 96.00, mode_tokens_cr = 94.44 \n",
      "In a bin out of 47 samples, 47  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "******************************************************** sentences_wise **********************************************************\n",
      "\n",
      "\n",
      "======================================================= bins =================================================\n",
      "\n",
      "\n",
      "param = bins , bin_num = 10 , total_samples_in_a_bin = 187 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=292, min_article_tokens=69, mean_article_tokens=144, median_article_tokens=136, mode_article_tokens=110 \n",
      "max_summary_tokens=105, min_summary_tokens=11, mean_summary_tokens=39, median_summary_tokens=35, mode_summary_tokens=20 \n",
      "max_tokens_cr = 91.58, min_tokens_cr = 5.19, mean_tokens_cr = 29.40, median_tokens_cr = 25.20, mode_tokens_cr = 23.08 \n",
      "In a bin out of 187 samples, 1  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 20 , total_samples_in_a_bin = 2451 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=25, mean_article_tokens=93, median_article_tokens=86, mode_article_tokens=75 \n",
      "max_summary_tokens=155, min_summary_tokens=9, mean_summary_tokens=38, median_summary_tokens=36, mode_summary_tokens=33 \n",
      "max_tokens_cr = 94.87, min_tokens_cr = 4.39, mean_tokens_cr = 44.10, median_tokens_cr = 42.70, mode_tokens_cr = 50.00 \n",
      "In a bin out of 2451 samples, 10  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 30 , total_samples_in_a_bin = 5270 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=271, min_article_tokens=23, mean_article_tokens=96, median_article_tokens=95, mode_article_tokens=100 \n",
      "max_summary_tokens=171, min_summary_tokens=8, mean_summary_tokens=45, median_summary_tokens=43, mode_summary_tokens=41 \n",
      "max_tokens_cr = 97.18, min_tokens_cr = 6.50, mean_tokens_cr = 49.41, median_tokens_cr = 48.15, mode_tokens_cr = 50.00 \n",
      "In a bin out of 5270 samples, 26  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 40 , total_samples_in_a_bin = 6560 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=299, min_article_tokens=28, mean_article_tokens=93, median_article_tokens=88, mode_article_tokens=77 \n",
      "max_summary_tokens=272, min_summary_tokens=12, mean_summary_tokens=49, median_summary_tokens=46, mode_summary_tokens=35 \n",
      "max_tokens_cr = 98.86, min_tokens_cr = 15.83, mean_tokens_cr = 54.74, median_tokens_cr = 53.93, mode_tokens_cr = 50.00 \n",
      "In a bin out of 6560 samples, 55  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 50 , total_samples_in_a_bin = 6781 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=293, min_article_tokens=22, mean_article_tokens=87, median_article_tokens=85, mode_article_tokens=86 \n",
      "max_summary_tokens=212, min_summary_tokens=13, mean_summary_tokens=51, median_summary_tokens=49, mode_summary_tokens=38 \n",
      "max_tokens_cr = 98.39, min_tokens_cr = 15.43, mean_tokens_cr = 60.77, median_tokens_cr = 60.43, mode_tokens_cr = 66.67 \n",
      "In a bin out of 6781 samples, 141  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param = bins , bin_num = 60 , total_samples_in_a_bin = 2521 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=29, mean_article_tokens=91, median_article_tokens=86, mode_article_tokens=68 \n",
      "max_summary_tokens=329, min_summary_tokens=10, mean_summary_tokens=57, median_summary_tokens=54, mode_summary_tokens=44 \n",
      "max_tokens_cr = 98.73, min_tokens_cr = 21.67, mean_tokens_cr = 63.97, median_tokens_cr = 64.21, mode_tokens_cr = 66.67 \n",
      "In a bin out of 2521 samples, 69  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 70 , total_samples_in_a_bin = 1048 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=330, min_article_tokens=36, mean_article_tokens=102, median_article_tokens=97, mode_article_tokens=105 \n",
      "max_summary_tokens=193, min_summary_tokens=25, mean_summary_tokens=67, median_summary_tokens=64, mode_summary_tokens=61 \n",
      "max_tokens_cr = 98.65, min_tokens_cr = 27.17, mean_tokens_cr = 67.38, median_tokens_cr = 68.00, mode_tokens_cr = 50.00 \n",
      "In a bin out of 1048 samples, 50  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 80 , total_samples_in_a_bin = 1328 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=202, min_article_tokens=25, mean_article_tokens=78, median_article_tokens=74, mode_article_tokens=74 \n",
      "max_summary_tokens=154, min_summary_tokens=17, mean_summary_tokens=56, median_summary_tokens=52, mode_summary_tokens=42 \n",
      "max_tokens_cr = 98.80, min_tokens_cr = 24.47, mean_tokens_cr = 71.84, median_tokens_cr = 72.92, mode_tokens_cr = 75.00 \n",
      "In a bin out of 1328 samples, 116  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 90 , total_samples_in_a_bin = 242 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=248, min_article_tokens=44, mean_article_tokens=98, median_article_tokens=93, mode_article_tokens=81 \n",
      "max_summary_tokens=154, min_summary_tokens=32, mean_summary_tokens=72, median_summary_tokens=66, mode_summary_tokens=66 \n",
      "max_tokens_cr = 98.65, min_tokens_cr = 37.12, mean_tokens_cr = 74.18, median_tokens_cr = 76.22, mode_tokens_cr = 66.67 \n",
      "In a bin out of 242 samples, 36  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 100 , total_samples_in_a_bin = 191 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=202, min_article_tokens=36, mean_article_tokens=83, median_article_tokens=79, mode_article_tokens=74 \n",
      "max_summary_tokens=168, min_summary_tokens=26, mean_summary_tokens=62, median_summary_tokens=58, mode_summary_tokens=74 \n",
      "max_tokens_cr = 99.02, min_tokens_cr = 36.59, mean_tokens_cr = 75.53, median_tokens_cr = 75.93, mode_tokens_cr = 53.19 \n",
      "In a bin out of 191 samples, 41  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "******************************************************** tokens_wise **********************************************************\n",
      "\n",
      "\n",
      "======================================================= bins =================================================\n",
      "\n",
      "\n",
      "param = bins , bin_num = 10 , total_samples_in_a_bin = 7 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=296, min_article_tokens=201, mean_article_tokens=255, median_article_tokens=252, mode_article_tokens=201 \n",
      "max_summary_tokens=25, min_summary_tokens=13, mean_summary_tokens=18, median_summary_tokens=20, mode_summary_tokens=20 \n",
      "max_tokens_cr = 9.95, min_tokens_cr = 4.39, mean_tokens_cr = 7.42, median_tokens_cr = 7.17, mode_tokens_cr = 4.39 \n",
      "In a bin out of 7 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 20 , total_samples_in_a_bin = 188 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=342, min_article_tokens=57, mean_article_tokens=153, median_article_tokens=152, mode_article_tokens=156 \n",
      "max_summary_tokens=59, min_summary_tokens=8, mean_summary_tokens=25, median_summary_tokens=25, mode_summary_tokens=20 \n",
      "max_tokens_cr = 20.00, min_tokens_cr = 10.32, mean_tokens_cr = 16.60, median_tokens_cr = 17.41, mode_tokens_cr = 20.00 \n",
      "In a bin out of 188 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 30 , total_samples_in_a_bin = 988 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=302, min_article_tokens=44, mean_article_tokens=121, median_article_tokens=117, mode_article_tokens=104 \n",
      "max_summary_tokens=85, min_summary_tokens=10, mean_summary_tokens=31, median_summary_tokens=31, mode_summary_tokens=30 \n",
      "max_tokens_cr = 30.00, min_tokens_cr = 20.18, mean_tokens_cr = 26.30, median_tokens_cr = 26.76, mode_tokens_cr = 30.00 \n",
      "In a bin out of 988 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 40 , total_samples_in_a_bin = 3114 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=319, min_article_tokens=30, mean_article_tokens=107, median_article_tokens=105, mode_article_tokens=105 \n",
      "max_summary_tokens=120, min_summary_tokens=10, mean_summary_tokens=38, median_summary_tokens=37, mode_summary_tokens=38 \n",
      "max_tokens_cr = 40.00, min_tokens_cr = 30.05, mean_tokens_cr = 35.83, median_tokens_cr = 36.11, mode_tokens_cr = 40.00 \n",
      "In a bin out of 3114 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 50 , total_samples_in_a_bin = 5366 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=293, min_article_tokens=26, mean_article_tokens=97, median_article_tokens=94, mode_article_tokens=81 \n",
      "max_summary_tokens=139, min_summary_tokens=13, mean_summary_tokens=44, median_summary_tokens=43, mode_summary_tokens=38 \n",
      "max_tokens_cr = 50.00, min_tokens_cr = 40.10, mean_tokens_cr = 45.45, median_tokens_cr = 45.57, mode_tokens_cr = 50.00 \n",
      "In a bin out of 5366 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 60 , total_samples_in_a_bin = 6073 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=330, min_article_tokens=23, mean_article_tokens=90, median_article_tokens=87, mode_article_tokens=75 \n",
      "max_summary_tokens=193, min_summary_tokens=13, mean_summary_tokens=50, median_summary_tokens=48, mode_summary_tokens=43 \n",
      "max_tokens_cr = 60.00, min_tokens_cr = 50.20, mean_tokens_cr = 55.23, median_tokens_cr = 55.24, mode_tokens_cr = 60.00 \n",
      "In a bin out of 6073 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 70 , total_samples_in_a_bin = 5215 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=287, min_article_tokens=23, mean_article_tokens=86, median_article_tokens=83, mode_article_tokens=77 \n",
      "max_summary_tokens=189, min_summary_tokens=14, mean_summary_tokens=55, median_summary_tokens=54, mode_summary_tokens=53 \n",
      "max_tokens_cr = 70.00, min_tokens_cr = 60.11, mean_tokens_cr = 64.91, median_tokens_cr = 64.81, mode_tokens_cr = 66.67 \n",
      "In a bin out of 5215 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 80 , total_samples_in_a_bin = 3487 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=216, min_article_tokens=22, mean_article_tokens=81, median_article_tokens=78, mode_article_tokens=71 \n",
      "max_summary_tokens=157, min_summary_tokens=16, mean_summary_tokens=60, median_summary_tokens=58, mode_summary_tokens=50 \n",
      "max_tokens_cr = 80.00, min_tokens_cr = 70.06, mean_tokens_cr = 74.65, median_tokens_cr = 74.49, mode_tokens_cr = 75.00 \n",
      "In a bin out of 3487 samples, 0  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 90 , total_samples_in_a_bin = 1624 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=366, min_article_tokens=23, mean_article_tokens=75, median_article_tokens=71, mode_article_tokens=62 \n",
      "max_summary_tokens=329, min_summary_tokens=20, mean_summary_tokens=63, median_summary_tokens=60, mode_summary_tokens=44 \n",
      "max_tokens_cr = 90.00, min_tokens_cr = 80.11, mean_tokens_cr = 84.40, median_tokens_cr = 84.09, mode_tokens_cr = 83.33 \n",
      "In a bin out of 1624 samples, 15  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n",
      "param = bins , bin_num = 100 , total_samples_in_a_bin = 532 \n",
      "=======================================================================\n",
      "\n",
      "Tokens:\n",
      "max_article_tokens=299, min_article_tokens=22, mean_article_tokens=73, median_article_tokens=68, mode_article_tokens=61 \n",
      "max_summary_tokens=272, min_summary_tokens=21, mean_summary_tokens=68, median_summary_tokens=64, mode_summary_tokens=46 \n",
      "max_tokens_cr = 99.12, min_tokens_cr = 90.08, mean_tokens_cr = 93.83, median_tokens_cr = 93.55, mode_tokens_cr = 90.91 \n",
      "In a bin out of 532 samples, 532  samples are greater than 90 tokens_CR threshold. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "####### Novelty checking:\n",
    "\n",
    "params = ['novelty','copy_precision','copy_recall']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for params_key in catergorized_info.keys():\n",
    "    print(\"\\n\\n\\n\\n******************************************************** %s **********************************************************\\n\\n\"%params_key) \n",
    "    for novelty_rouge_set in catergorized_info[params_key].keys():### keys are rouge-1,2,3,4,L:\n",
    "            param_bins = catergorized_info[params_key][novelty_rouge_set] ### bins of rouge_N\n",
    "            print(\"======================================================= %s =================================================\\n\\n\"%novelty_rouge_set)\n",
    "            for i in range(10):\n",
    "                cr_thr_count = 0 ##### if we want to get for every bin:\n",
    "                bin_num = (i+1)*10\n",
    "                article_tokens = []\n",
    "                article_sents = []\n",
    "\n",
    "                summary_tokens = []\n",
    "                summary_sents = []\n",
    "\n",
    "                cr_sents = []\n",
    "                cr_tokens = []\n",
    "                \n",
    "                #print(\"param_bins: \",param_bins[str(i)].keys())\n",
    "                list_samples = param_bins[str(i)]['samples']\n",
    "                #print(\"total samples in a Bin = %d\"%len(list_samples))\n",
    "                \n",
    "                for sample in list_samples:\n",
    "                    temp_article_tokens = corpus_info[sample]['article']['tokens_wise']\n",
    "                    temp_article_sents  = corpus_info[sample]['article']['sentences_wise']\n",
    "\n",
    "                    temp_summary_tokens = corpus_info[sample]['summary']['tokens_wise']\n",
    "                    temp_summary_sents  = corpus_info[sample]['summary']['sentences_wise']\n",
    "\n",
    "                    article_sents.append(len(temp_article_sents))\n",
    "                    article_tokens.append(len(temp_article_tokens))\n",
    "\n",
    "                    summary_sents.append(len(temp_summary_sents))\n",
    "                    summary_tokens.append(len(temp_summary_tokens))\n",
    "\n",
    "                    \n",
    "                    cr_sents.append((len(temp_summary_sents)/float(len(temp_article_sents)))*100) ## sentences CR\n",
    "                    cr_tokens.append((len(temp_summary_tokens)/float(len(temp_article_tokens)))*100) ## Tokens CR\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    t1 = (len(temp_summary_tokens)/float(len(temp_article_tokens)))*100 ## tokens;\n",
    "                    cr_range = 90             \n",
    "                    if(t1>=cr_range):\n",
    "                        #print(\"t1 = %d\"%t1)\n",
    "                        #print(\"sumamry tokens=%d, article tokens=%d \"%((len(temp_summary_tokens), len(temp_article_tokens))))\n",
    "                        cr_thr_count+=1\n",
    "\n",
    "\n",
    "                ############# Tokens ################\n",
    "\n",
    "                max_article_tokens    = max(article_tokens)\n",
    "                min_article_tokens    = min(article_tokens)\n",
    "                mean_article_tokens   = np.mean(np.array(article_tokens))\n",
    "                median_article_tokens = np.median(article_tokens)\n",
    "                mode_article_tokens   = stats.mode(article_tokens)[0][0]\n",
    "\n",
    "                max_summary_tokens    = max(summary_tokens)\n",
    "                min_summary_tokens    = min(summary_tokens)\n",
    "                mean_summary_tokens   = np.mean(np.array(summary_tokens))\n",
    "                median_summary_tokens = np.median(summary_tokens)\n",
    "                mode_summary_tokens   = stats.mode(summary_tokens)[0][0]\n",
    "\n",
    "\n",
    "                ##################### Sentences #################\n",
    "                max_article_sents     = max(article_sents)\n",
    "                min_article_sents     = min(article_sents)\n",
    "                mean_article_sents    = np.mean(np.array(article_sents))\n",
    "                median_article_sents  = np.median(article_sents)\n",
    "                mode_article_sents    = stats.mode(article_sents)[0][0]\n",
    "   \n",
    "                \n",
    "                max_summary_sents     = max(summary_sents)\n",
    "                min_summary_sents     = min(summary_sents)\n",
    "                mean_summary_sents    = np.mean(np.array(summary_sents))\n",
    "                median_summary_sents  = np.median(summary_sents)\n",
    "                mode_summary_sents    = stats.mode(summary_sents)[0][0]\n",
    "                \n",
    "                \n",
    "                ### Compression Ratio = (length of Summary)/(length of Original Text) ######\n",
    "\n",
    "                max_sents_cr          = max(cr_sents)\n",
    "                min_sents_cr          = min(cr_sents)\n",
    "                mean_sents_cr         = np.mean(cr_sents)\n",
    "                median_sents_cr       = np.median(cr_sents)\n",
    "                mode_sents_cr         = stats.mode(cr_sents)[0][0]\n",
    "                \n",
    "                max_tokens_cr         = max(cr_tokens)\n",
    "                min_tokens_cr         = min(cr_tokens)\n",
    "                mean_tokens_cr        = np.mean(cr_tokens)\n",
    "                median_tokens_cr      = np.median(cr_tokens)\n",
    "                mode_tokens_cr        = stats.mode(cr_tokens)[0][0]\n",
    "                \n",
    "                #print(mode_sents_cr, mode_tokens_cr)\n",
    "                \n",
    "                print(\"param = %s , bin_num = %d , total_samples_in_a_bin = %d \"%(novelty_rouge_set, bin_num, len(list_samples)) )\n",
    "                print(\"=======================================================================\\n\")\n",
    "                print(\"Tokens:\")\n",
    "                print(\"max_article_tokens=%d, min_article_tokens=%d, mean_article_tokens=%d, median_article_tokens=%d, mode_article_tokens=%d \"%(max_article_tokens, min_article_tokens, mean_article_tokens, median_article_tokens, mode_article_tokens)) \n",
    "                print(\"max_summary_tokens=%d, min_summary_tokens=%d, mean_summary_tokens=%d, median_summary_tokens=%d, mode_summary_tokens=%d \"%(max_summary_tokens, min_summary_tokens, mean_summary_tokens, median_summary_tokens, mode_summary_tokens))\n",
    "                print(\"max_tokens_cr = %.2f, min_tokens_cr = %.2f, mean_tokens_cr = %.2f, median_tokens_cr = %.2f, mode_tokens_cr = %.2f \"%(max_tokens_cr, min_tokens_cr, mean_tokens_cr, median_tokens_cr, mode_tokens_cr))\n",
    "                # len(list_samples)== param_bins[str(i)]['count']\n",
    "                #print(\"total samples in a bin = %d, Tokens_CR_threshold_count = %d samples which are greater than %d CR threshold. \"%(param_bins[str(i)]['count'] ,cr_thr_count, cr_range))\n",
    "                print(\"In a bin out of %d samples, %d  samples are greater than %d tokens_CR threshold. \"%(param_bins[str(i)]['count'] ,cr_thr_count, cr_range))\n",
    "                print(\"\\n\")\n",
    "                \n",
    "                #print(\"Sentences:\")\n",
    "                #print(\"max_article_sents=%d, min_article_sents=%d, mean_article_sents=%d, median_article_sents=%d, mode_article_sents=%d \"%(max_article_sents,min_article_sents,mean_article_sents, median_article_sents, mode_article_sents))\n",
    "                #print(\"max_summary_sents=%d, min_summary_sents=%d, mean_summary_sents=%d, median_summary_sents=%d, mode_summary_sents=%d\"%(max_summary_sents,min_summary_sents,mean_summary_sents, median_summary_sents, mode_summary_sents))\n",
    "                #print(\"max_sents_cr=%.2f, min_sents_cr=%.2f, mean_sents_cr=%.2f, median_sents_cr=%.2f, mode_sents_cr=%.2f \"%(max_sents_cr, min_sents_cr, mean_sents_cr, median_sents_cr, mode_sents_cr))\n",
    "\n",
    "                #print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
